# Interpretive Conditions Theory
## Concept Ledger (Canonical, Private)
**Version 2.0 | January 2026**

**Purpose of this document**
This ledger is the authoritative semantic contract for Interpretive Conditions Theory (ICT).
It governs meaning across all public, practitioner, and academic artifacts.

* If a claim is **not represented here**, it is **not yet part of the theory**
* Public explanations may simplify language, but **may not alter meaning**
* Academic arguments may extend or defend concepts, but **may not redefine them without ledger revision**
* When working paper and ledger conflict, **ledger is authoritative**

---

## CONCEPT CLASSIFICATION

* **CORE concepts** define the identity and causal logic of ICT
* **SUPPORTING concepts (ICT-owned)** refine, operationalize, or extend the core
* **IMPORTED supporting concepts** are explicitly borrowed, bounded, and non-owned

**Terminological Note:**
When a term appears in both lowercase (general usage) and capitalized (specific construct), the capitalized version refers to the formal ICT concept. For example: "norms" (observable instances) vs. "Norms & Expectations" (domain representing collective pattern).

---

# CORE CONCEPTS (ICT-OWNED)

These concepts are **identity-defining**.
Removing or collapsing any of them dissolves the theory.

---

## Interpretive Conditions Theory (ICT)

**Canonical Definition**
An interpretive-institutional theory of organizing that explains persistent patterns of behavior as responses to conditions people interpret as legitimate, risky, or worthwhile over time, with patterns persisting only through continuous coordinated reenactment.

**Core Claim**
Persistence in human systems arises from learned interpretation of conditions, not from plans, attitudes, or enforcement alone.

**Non-Claims**

* Not predictive (does not guarantee outcomes from interventions)
* Not prescriptive (does not specify optimal organizational designs)
* Not a theory of motivation or personality (focuses on external conditions, not internal traits)
* Not a field-level diffusion theory (explains within-organization dynamics, not cross-organizational adoption)

---
Perfect. That's a much clearer specification. Let me draft the revised **Conditions** definition for the ledger that addresses this vulnerability:

---

## **Revised Conditions Definition**
## Conditions

**Canonical Definition**
External, observable features of the environment that people encounter and interpret when deciding how to act. Conditions shape meaning often implicitly and sometimes prior to explicit deliberation. Conditions function recursively as both input and output.

**Key Properties**

* **External and observable** (not internal mental states or private thoughts)
* Include norms, rules, tools, feedback, and constraints
* May constrain action directly (capacity, authority, tools) or indirectly through interpretation
* Function recursively: conditions → interpretation → response → new conditions

**What Qualifies as "Observable"**

Observable means **capable of being perceived by a person through any sense** (sight, hearing, touch, smell, etc.), not that it must be observed by all people or even noticed by anyone in particular.

**Observable conditions include:**
* What someone says or does (behavior, speech, writing)
* What tools/systems allow or prevent (affordances, constraints)
* What gets measured and displayed (dashboards, reports, reviews)
* Physical artifacts (office layout, resources available, posted signs)
* Temporal patterns (meeting schedules, deadlines, response times)
* Outward expressions (facial expressions, tone of voice, body language)
* What's absent or withheld (silence, missing information, who's not invited)

**Not observable conditions (internal states):**
* What someone thinks but doesn't express
* Private feelings (fear, anxiety, excitement) before any outward expression
* Internal cognitive processes (how someone reasons through a decision)
* Unspoken intentions

**Clarifying Boundary Cases:**

* **Fear (internal)** is not a condition → **Outward signs of fear** (trembling, avoiding eye contact, hesitation) ARE conditions
* **Internal dialog** is not a condition → **What someone says aloud** IS a condition
* **Private belief** is not a condition → **Public statement of belief** IS a condition
* **Cognitive framing** is not a condition → **Language used in tools/documents** that shapes framing IS a condition

**Why This Distinction Matters:**

ICT focuses on what's available in the environment for interpretation, not what's happening inside individual minds. This is both:
1. **Methodologically practical** - We can study observable conditions; we can't directly access internal states
2. **Theoretically principled** - Patterns emerge through responses to shared environmental features, not private thoughts

**Important Nuance:**

Once an internal state becomes **expressed** (spoken, written, enacted in behavior), it becomes an observable condition that others can respond to. The theory doesn't deny internal states exist—it focuses on what's available for collective interpretation and response.

**Conditions Include Norms (lowercase):**

When ICT says conditions include "norms," it means enacted, observable instances of normative behavior: stories told, reactions observed, visible patterns of inclusion/exclusion. These are discrete events that can be perceived.

This is distinct from the **Norms & Expectations domain** (capitalized), which is the collective pattern that emerges when many such instances converge over time. Individual norm enactments are conditions; the collective pattern they form is a domain.

**Recursive Note:**

Conditions include norms (which are socially constructed), but norms become conditions when they're **enacted and observable**. A norm that lives only in people's heads isn't a condition. A norm that's expressed through stories, sanctions, or patterns of behavior IS a condition because it can be observed and responded to.

---

## Legitimacy

**Canonical Definition**
The shared sense of what actions are acceptable, safe, or worth the effort within a system, shaping what people feel able to do regardless of formal permission.

**Key Properties**

* Learned through experience, not declared
* Inferred from consequences observed when actions are taken
* Operates implicitly (often without conscious deliberation)

**States of Legitimacy (Spectrum)**

* **Contested:** Actions require explicit justification or deliberation. "Should I do this? What will happen?" This is where most organizational change lives.
* **Routine:** Actions are normal and expected but still conscious. "This is what we do here."
* **Taken-for-granted:** Actions are so obvious that alternatives aren't considered. "Of course we do it this way." This is legitimacy's most powerful state—when it becomes invisible.

**Ontological Status**

* **Phenomenological:** A felt sense of whether an action is worth the likely consequence
* **Relational:** How meanings are negotiated, reinforced, or corrected in interaction with others
* **Institutional:** When action becomes obvious and legitimacy collapses into structure—enacted without thought

**Multi-Level Measurement Framework**

ICT's legitimacy construct aligns with recent institutional theory's multi-level operationalization (Haack et al., 2021):

**Individual Level (Phenomenological):**
Measured through individual assessment of whether actions are safe, acceptable, and worthwhile.

**Meso Level (Relational/Consensus):**
Measured as agreement between individuals' legitimacy beliefs. High consensus = distributed memory has converged. Low consensus = interpretations remain contested.

**Macro Level (Institutional/Validity):**
Measured as taken-for-granted status through authorization (leadership endorsement, policy inclusion), endorsement (peer adoption), and institutionalization (alternatives aren't considered).

**Operationalization Approaches:**

1. **Individual legitimacy (Propriety equivalent):**
   - Survey items: "Attempting [practice] is safe here" / "acceptable here" / "worth the effort"
   - Measures felt sense of legitimacy for individuals

2. **Collective consensus:**
   - Calculate variance/standard deviation in individual responses
   - Low variance = high consensus (routine or taken-for-granted)
   - High variance = low consensus (contested)

3. **Institutional validity:**
   - Leadership endorsement (observable authorization)
   - Policy inclusion (formal codification)
   - Peer adoption rates (social endorsement)
   - Lack of alternatives considered (taken-for-grantedness)

**Spectrum Operationalization:**

- **Contested legitimacy:** High variance in individual beliefs (SD > 1.5 on 7-point scale); active debate or enforcement required
- **Routine legitimacy:** Moderate consensus (SD = 0.8-1.5); general acceptance but conscious
- **Taken-for-granted legitimacy:** Very high consensus (SD < 0.8); automatic, unreflective compliance; alternatives not considered

**Detecting Contested Equilibrium:**

Contested equilibrium is detected when:
- Behavioral compliance is high (practice is routinely enacted)
- Validity is high (leaders endorse, policies include, peers appear to adopt)
- Consensus is low (high variance in individual legitimacy beliefs)
- Individual legitimacy is low (people privately believe practice is not safe/acceptable/worthwhile)

This measurement approach enables empirical distinction between coordination stability and legitimacy convergence.

**Citation:**
Haack, P., Schilke, O., & Zucker, L. G. (2021). Legitimacy revisited: Disentangling propriety, validity, and consensus. *Journal of Management Studies, 58*(3), 749-781.

---

## Interpretation

**Canonical Definition**
The process through which individuals assess environmental cues and form legitimacy judgments about what actions are safe, acceptable, and worthwhile.

**Theoretical Positioning**

ICT is not a theory OF interpretation. ICT is a theory that USES interpretation as a mechanism. Just as ICT borrows "legitimacy" from institutional theory, ICT borrows "interpretation" from existing psychological and organizational research on judgment and decision-making.

**Interpretation Mechanisms (Imported)**

ICT uses **cue-based heuristic processing** as specified in:
- **Tost (2011):** Passive mode legitimacy judgments using heuristics
- **Chaiken (1987):** Heuristic-systematic model of information processing  
- **Bitektine (2011); Deephouse et al. (2017):** Cue-based legitimacy assessment

**How Interpretation Works in ICT**

**Five-Step Process:**

1. **Cue Observation:** People encounter observable signals from environmental conditions across six domains
2. **Heuristic Application:** Simple decision rules are triggered automatically (authority, consensus, consequence, consistency, feasibility heuristics)
3. **Legitimacy Judgment:** Assessment forms along three dimensions (safe/risky, acceptable/unacceptable, worthwhile/not worthwhile)
4. **Response:** Behavior is shaped by legitimacy judgment (enact, avoid, hesitate)
5. **New Conditions Created:** Responses become observable to others, creating new cues (recursive loop)

**Two Processing Modes**

**Passive/Heuristic Mode (Primary):**
- Low cognitive effort
- Quick, quasi-automatic processing
- Uses simple decision rules triggered by environmental cues
- Operates in most day-to-day organizational situations
- Example: "Leaders emphasize X → X must be important" (authority heuristic activated without deliberation)

**Evaluative/Systematic Mode (Secondary):**
- High cognitive effort  
- Deliberate, careful analysis
- Occurs when: high personal stakes, contradictory cues, novel situations, prompted to justify
- Example: Carefully weighing career implications of speaking up in meeting

**Both modes can operate simultaneously**—people may use heuristics while also engaging in some systematic processing.

**Specific Heuristics People Use**

**Authority Heuristic:**
- "What leaders prioritize is legitimate"
- "Leadership endorsement signals safety"
- Triggered by: Leadership attention, public statements, what gets emphasized

**Consensus/Social Proof Heuristic:**
- "What everyone does is safe"
- "People like me do X"
- Triggered by: Peer behavior, stories about others, visible norms

**Consequence Heuristic:**
- "What gets rewarded is legitimate"
- "What gets punished is risky"
- Triggered by: Observed outcomes (promotions, sanctions, recognition)

**Consistency Heuristic:**
- "Consistency signals what truly matters"
- "Alignment between words and actions is trustworthy"
- Triggered by: Cross-domain cue alignment or misalignment

**Feasibility Heuristic:**
- "If it's structurally possible, it might be expected"
- "If it's impossible despite words, it's not really legitimate"
- Triggered by: Capacity availability, tool capabilities, authority boundaries

**Anchoring on "Normal":**
- "Assess by comparing to what's typical"
- "High deviation from normal triggers scrutiny"
- Triggered by: Observing average, most common, or most recent patterns

**Three Legitimacy Dimensions**

Drawing on Tost's (2011) instrumental/relational/moral framework, ICT assesses legitimacy along three dimensions reframed for organizational application:

**1. Safe? (Instrumental + Relational)**
- "Will I be punished for attempting this?"
- "Will this harm my standing or relationships?"
- "Is this risky given what I've observed happen to others?"

**2. Acceptable? (Relational + Moral)**
- "Is this what people like me do here?"
- "Will I be excluded or sanctioned if I don't comply?"
- "Does this fit with how we work?"

**3. Worthwhile? (Instrumental + Moral)**
- "Is this worth the effort given competing demands?"
- "Does this align with what I believe is meaningful?"
- "Is this real work or compliance theater?"

**How Interpretations Converge (or Don't)**

**Convergence → Consensus:**

When many people encounter **similar cues** and apply **similar heuristics**, interpretations converge:
- Most observe "speaking up leads to criticism" (similar cues)
- Most apply consequence heuristic: "risky actions are illegitimate" (similar heuristic)
- Most interpret "speaking up is risky here" (convergent judgment)
- Most avoid speaking up (coordinated response)
- **Distributed memory forms:** "We don't speak up here"

**Divergence → Contested Legitimacy:**

When people encounter **contradictory cues** OR weight **different heuristics**, interpretations diverge:
- Leaders SAY "speak up" (authority cue: legitimate)
- Peers WHO speak up get criticized (consequence cue: illegitimate)
- Some weight authority cues more → judge "legitimate"
- Some weight consequence cues more → judge "illegitimate"
- **No consensus forms** → Legitimacy remains contested

**Why Cue Consistency Across Domains Matters:**

When domains align (send consistent cues):
- All heuristics point same direction
- Authority + Consequence + Consensus + Feasibility + Consistency cues all signal same legitimacy judgment
- Interpretations converge quickly → High consensus → Taken-for-granted status emerges

When domains contradict (send inconsistent cues):
- Heuristics trigger conflicting judgments
- Authority says one thing, consequences show another, feasibility limits third option
- Interpretations remain divergent → Low consensus → Contested legitimacy persists

**Key Properties**

* **Often implicit** - Not conscious deliberation; heuristics operate automatically
* **Socially situated** - Shaped by observable peer behavior, stories, and interaction
* **Precedes deliberate choice** - Shapes what feels possible before weighing options
* **Operates through heuristics** - Simple decision rules triggered by environmental cues
* **Creates recursive loop** - Responses become new conditions that others interpret

**What's Distinctive About ICT's Use of Interpretation**

1. **Specifies cue sources:** Cues come from six specific domains, each operating through three mechanisms (structural, signaling, cognitive)
2. **Explains persistent contestation:** Contradictory cues across domains can sustain contested legitimacy indefinitely (not just temporary ambiguity)
3. **Distinguishes cue-based from outcome-based learning:** Learning about legitimacy BEFORE trying (from cues) vs. AFTER trying (from results)
4. **Makes domain consistency testable:** Measure cue consistency across domains; predict legitimacy convergence
5. **Connects interpretation to coordination:** Behavioral compliance (coordination) can persist even when legitimacy interpretations remain contested

**Sources**

- Tost, L. P. (2011). An integrative model of legitimacy judgments. *Academy of Management Review, 36*(4), 686-710.
- Chaiken, S. (1987). The heuristic model of persuasion. In M. P. Zanna, J. M. Olson, & C. P. Herman (Eds.), *Social influence: The Ontario Symposium* (Vol. 5, pp. 3–39). Hillsdale, NJ: Lawrence Erlbaum.
- Bitektine, A. (2011). Toward a theory of social judgments of organizations: The case of legitimacy, reputation, and status. *Academy of Management Review, 36*(1), 151-179.
- Deephouse, D. L., Bundy, J., Tost, L. P., & Suchman, M. C. (2017). Organizational legitimacy: Six key questions. In R. Greenwood, C. Oliver, T. B. Lawrence, & R. E. Meyer (Eds.), *The SAGE Handbook of Organizational Institutionalism* (2nd ed., pp. 27-54). SAGE.

---

## Response

**Canonical Definition**
The actions people take—or avoid—based on their interpretation of legitimacy and risk.

**Response Types**

* **Reproduction:** Enacting the existing pattern (structure persists through reenactment)
* **Variation:** Slight deviation from the pattern (structure evolves gradually)
* **Violation / Testing:** Breaking the pattern to test what happens (reveals structure's strength)
* **Coordinated change:** Enough people enact differently that a new pattern emerges (structure dissolves or transforms)

---

## Agency

**Canonical Definition**
The individual capacity to choose among available responses within the constraints imposed by structural conditions. Agency is bounded—shaped by past experiences, present structural context, and perceived future possibilities.

**Theoretical Positioning**

ICT is not a theory OF agency. ICT is a theory that USES agency as a mechanism. Agency explains variation in individual responses to the same environmental conditions.

**Agency Mechanisms (Imported from Bounded Agency Theory)**

ICT uses the bounded agency framework as specified in:
- Evans, K. (2007). Concepts of bounded agency in education, work, and the personal lives of young adults. *International Journal of Psychology, 42*(2), 85-93.
- Evans, K. (2017). Bounded agency in professional lives. In M. Goller & S. Paloniemi (Eds.), *Agency at Work: An Agentic Perspective on Professional Learning and Development* (pp. 17-36). Springer.

**Ontological Status: Individual, Not Collective**

- Agency resides with individual people, not groups or organizations
- Parallel to distributed memory: memory stored in individuals (dispersed), agency exercised by individuals (dispersed)
- "Organizational agency" is shorthand for aggregated individual exercises of agency
- Coordination emerges from many individual responses, not from collective will or organizational consciousness

**How Agency Operates**

**1. Agency is Bounded**

"Agency is a socially situated process, shaped by the experiences of the past, the chances present in the current moment and the perceptions of possible futures" (Evans, 2007, p. 89)

Agency operates WITHIN constraints, not against them:
- Structural conditions define the range of possible responses
- Agency determines which response within that range
- Not unlimited freedom—choice among available (constrained) options
- Constraints shape what feels possible, safe, acceptable, and worthwhile

**2. What Bounds Agency (Structural Constraints)**

Six structural domains impose constraints that narrow the perceived possibility space:

**Capacity Domain:**
- Lack of time → "I cannot attempt X even if I want to"
- Lack of authority → "I am not allowed to do X"
- Lack of resources → "X is not possible with what I have"

**Tools & Processes Domain:**
- Tools don't support action → "The system will not let me do X"
- Processes block paths → "There is no way to accomplish X through official channels"

**Data & Feedback Domain:**
- No visibility into results → "I cannot tell if X would work"
- Metrics don't measure what matters → "X will not show up in evaluations"

**Skills & Knowledge Domain:**
- Lack competence → "I do not know how to do X"
- No training provided → "No one taught me X"

**Motivation & Values Domain:**
- Consequences deter → "If I do X, I will be punished"
- No rewards → "X will not be recognized"

**Norms & Expectations Domain:**
- Social sanction → "If I do X, I will be excluded"
- Identity constraint → "People like me do not do X"

These constraints operate through:
- **Direct limitation:** Resource/structural impossibility
- **Cognitive framing:** Narrowing what comes to mind as possible
- **Perceived risk:** Consequences make attempts feel too dangerous
- **Horizon narrowing:** Options don't appear on radar as possibilities

**3. What Enables Agency (What Creates Variation in Responses)**

People exercise agency differently based on their position, resources, and perceptions:

**Perceived Possibilities ("Personal Horizons"):**
- What they believe is achievable given their position
- Shaped by past experiences (what they've seen work/fail)
- Different mental models and interpretations of same cues
- Access to different information about what's possible

**Available Resources:**
- Economic resources (financial security, ability to take risks)
- Social resources (networks, relationships, support systems)
- Cultural resources (credentials, legitimacy, positional authority)
- These enable some people to attempt responses others cannot

**Risk Tolerance:**
- Ability to absorb consequences of deviation
- Can afford to fail (have safety nets)
- Less to lose (secure position, or already planning to leave)
- More to gain (deviation aligns with values/identity)

**Temporal Horizon ("Shadow of the Future"):**
- Expected duration of relationship with organization
- Anticipated career trajectory
- Whether investment will pay off
- Short horizon → less constrained by long-term consequences
- Long horizon → more constrained OR more committed

**Identity and Values:**
- Professional identity ("This is what engineers do")
- Moral convictions ("This is wrong, I must act")
- Alignment with personal standards
- Willingness to accept social costs for values

**Different positions, resources, and perceptions → Different perceived possibility spaces → Different exercises of agency in response to same structural conditions**

**4. Agency as Process**

Agency is not a fixed trait—it is continuously shaped by structural context:

**The Cycle:**
1. **Past experiences** shape what feels possible and what risks are acceptable
2. **Current structural conditions** enable or constrain options available now
3. **Perceived futures** influence assessment of whether action is worthwhile
4. **Agency exercised** (choice made within available constrained options)
5. **New experiences** feed back into future perceptions of possibilities

This is a continuous, recursive process. Each exercise of agency creates new experiences that shape future perceptions of what's possible.

**When Agency Produces Different Outcomes**

**The Core Mechanism:**

**Structural conditions constrain the RANGE of possible responses.**
**Agency determines WHICH response within that range.**

**What Conditions DON'T Determine:**
- Exactly which response each person chooses
- How each individual interprets the same cues
- Which heuristics each person weights most heavily
- Whether someone tests boundaries or complies fully
- Who exits, who advocates, who waits

**What Conditions DO Constrain:**
- What feels possible, safe, acceptable, worthwhile
- How costly deviation is
- What consequences follow attempts
- The outer boundaries of the range of responses

**Example: Same Structural Conditions, Different Individual Responses**

**Situation:** Contradictory domain signals
- Leadership says "innovate"
- Innovators who speak up get criticized
- No time allocated for experiments
- Metrics measure only efficiency

**Different Individual Responses (all within structural constraints):**

- **Person A:** Complies minimally, focuses on efficiency
  - High value on security, low risk tolerance
  - Interprets consequence cues > authority cues
  
- **Person B:** Innovates quietly in spare time
  - High risk tolerance, secure position
  - Can absorb criticism, values experimentation
  
- **Person C:** Advocates loudly for change
  - Strong moral conviction that innovation is essential
  - Willing to accept social cost
  
- **Person D:** Exits to join different organization
  - High mobility, resources for alternatives
  - Temporal horizon shortened
  
- **Person E:** Waits and watches
  - Conserving agency for better moment
  - Low risk tolerance, wants to see what happens to others

**All responses are within the structurally bounded possibility space** (no one builds a competitor product on company time—that's outside the range). **But individuals vary in which constrained option they choose based on their position, resources, and interpretation.**

This variation is agency operating within constraints.

**How Agency Relates to Structure Change**

**The Process of Change:**

Structures change through aggregated individual agency, not through heroic individuals overcoming all constraints.

**Change Happens When:**

1. **Structural conditions permit some room for variation**
   - Domain constraints are not maximally tight
   - Some responses within the range deviate from current pattern
   - Consequences of deviation are bearable for some

2. **Enough individuals perceive new possibilities**
   - Interpretation shifts (different cue weighting)
   - Demonstrators prove feasibility ("If Jamie can do X, maybe I can too")
   - Mental models update based on observation

3. **Enough individuals exercise agency similarly**
   - Coordinated variation (not necessarily coordinated consciously)
   - Many people independently choose similar responses
   - Aggregated responses create recognizable new pattern

4. **New pattern becomes observable to others**
   - Others see deviation happening without punishment
   - Cues shift (what's "normal" changes)
   - Perceived possibility space expands for others

5. **Distributed memory updates**
   - New pattern gets encoded as legitimate
   - "This is how we do things here" shifts
   - Structure has transformed through aggregated agency

**Change Does NOT Require:**
- Heroic individuals overcoming all structural constraints
- Collective organizational will or consciousness
- Breaking free of structure entirely
- Unlimited agency or entrepreneurship

**Change DOES Require:**
- Structural conditions permitting some variation (room within range)
- Enough individuals perceiving possibilities and attempting responses
- Aggregated responses creating recognizable new pattern
- Distributed memory updating to encode new pattern

**Resolving the Determinism Problem**

**The Apparent Paradox:**
"If conditions shape behavior so powerfully, where is agency? How does change ever happen?"

**The Resolution (Bounded Agency Framework):**

**ICT is neither deterministic nor voluntaristic:**

**NOT Deterministic:**
- Conditions constrain the range, they don't determine the exact outcome
- Agency produces variation within constraints
- Different individuals respond differently to same conditions
- Change is possible when structural room exists and agency aggregates

**NOT Voluntaristic:**
- Agency doesn't operate unconstrained
- Individual heroism alone cannot override tight structural constraints
- Structure shapes what feels possible, safe, worthwhile
- Change requires both structural permission and aggregated agency

**ICT Shows How Structure and Agency Operate Together:**
- Structure constrains the range of responses that feel possible
- Agency produces variation in responses within that range
- Aggregated responses reproduce or transform structure
- Changed structure creates new constraints for future agency
- **Continuous, recursive process—structure and agency are inseparable**

**Key Properties**

* **Individual:** Agency resides with persons, not collectives or organizations
* **Bounded:** Constrained by structural conditions from six domains, not unlimited
* **Processual:** Continuously shaped by past experiences, present context, perceived futures
* **Varies by position:** Different resources and constraints create different possibility spaces
* **Produces variation:** Same conditions yield different individual responses
* **Aggregates to patterns:** Many individual responses create emergent structure
* **Enables change:** When structural room exists and agency aggregates, patterns transform

**Core Role in ICT**

Agency is the mechanism through which structures are reproduced or changed. Every moment of interpretation and response is an opportunity for:
- **Reproduction:** Choosing responses that reenact existing pattern
- **Variation:** Choosing responses that slightly deviate
- **Violation/Testing:** Choosing responses that break pattern to test consequences
- **Coordinated change:** Enough people choosing deviation that new pattern emerges

Agency explains WHY patterns are not deterministic and HOW change is possible, while bounded agency explains WHY change is not guaranteed and WHEN it occurs (structural room + aggregated responses).

**Sources**

- Evans, K. (2007). Concepts of bounded agency in education, work, and the personal lives of young adults. *International Journal of Psychology, 42*(2), 85-93.
- Evans, K. (2017). Bounded agency in professional lives. In M. Goller & S. Paloniemi (Eds.), *Agency at Work: An Agentic Perspective on Professional Learning and Development* (pp. 17-36). Springer.
- Biesta, G., & Tedder, M. (2007). Agency and learning in the life course: Towards an ecological perspective. *Studies in the Education of Adults, 39*(2), 132-149.

---

## Structures (as Continuous Enactment)

**Canonical Definition**
Patterns continuously recreated through coordinated action. Structures exist only in ongoing enactment and dissolve when reproduction stops.

**CRITICAL CLARIFICATION: Structure = Institution**

"Structure" (ICT) and "Institution" (Institutional Theory) refer to the **same phenomenon**: patterns maintained through legitimacy-based continuous enactment.

**Why different terms:**
- Different scholarly traditions (sociology/macro-organizational vs. applied organizational behavior)
- Different emphasis (IT: stability, resilience; ICT: process, continuous enactment)
- Same mechanisms, different vocabulary

**ICT's relationship to Institutional Theory:**
- **NOT:** A different ontological entity or competing framework
- **BUT:** Mechanistic specification and operational elaboration of institutional theory
- **Analogy:** Institutional Theory : ICT :: Newtonian Physics : Engineering Mechanics

**What ICT contributes:**
1. **Distributed Memory** - HOW taken-for-granted forms (dispersed across individuals, no central storage)
2. **Six Domains** - WHERE cues come from (specific organizational conditions)
3. **Cue-Based Interpretation** - HOW legitimacy is learned (observation → heuristics → judgment)
4. **Contested Equilibrium** - HOW coordination without legitimacy forms and persists (domain misalignment)
5. **Bounded Agency** - HOW agency operates within structural constraints
6. **Process Emphasis** - Structuring (verb) over structure (noun), no endpoint

**Measurement methods transfer directly from Institutional Theory:**
- Tolbert & Zucker's (1996) three-stage framework
- Scott's (2001) three pillars (regulative, normative, cultural-cognitive)
- Haack, Schilke, & Zucker's (2021) multi-level legitimacy measurement

**CRITICAL CLARIFICATION: Multi-Level Structuring**

**Structuring happens at ALL levels simultaneously:**
- Individual interactions (micro)
- Family patterns
- Team patterns
- Organizational patterns
- Industry/field patterns
- Professional patterns
- Political patterns
- Cultural/societal patterns

**There is NO scope restriction.** The same mechanisms (cues, interpretation, legitimacy, distributed memory, continuous enactment) operate at every level.

**Individuals exist within LAYERED, OVERLAPPING structures (palimpsest):**

A person simultaneously participates in:
- Family structure ("how we do dinner")
- Work team structure ("how we do stand-ups")
- Organizational structure ("how we do performance reviews")
- Professional structure ("how engineers work")
- Industry structure ("how tech companies operate")
- Cultural structure ("how Americans greet")
- Political structure ("how we vote")

**All operating at once. All using the same structuring mechanisms. All continuously enacted.**

**Example: Marriage works at multiple levels:**
- **Societal level:** "Marriage" as institution (laws, norms, cultural expectations)
- **Relationship level:** "Our marriage" as structure (how THIS couple enacts the pattern)
- **Individual level:** "Being married" as identity/role (how I enact spouse behavior)

**Same phenomenon (continuous enactment through legitimacy), different scales.**

**CRITICAL CLARIFICATION: Structure (Noun) vs. Structuring (Verb)**

**Structure as noun** is a communication convenience. What actually happens is **structuring** (verb)—the continuous process of enactment.

**Structuring is ALWAYS occurring** when patterns are being reproduced:
- People read cues
- People form legitimacy judgments  
- People respond
- Responses become new cues
- Pattern continues through continuous enactment

**All patterns being continuously enacted ARE structures.** They vary in CHARACTER, not EXISTENCE:
- **Degree of coordination** (behavioral convergence)
- **Degree of legitimacy consensus** (interpretive convergence)
- **Degree of taken-for-grantedness** (cognitive pillar strength)
- **Degree of stability** (resistance to change)

**Common Misconception to AVOID:**

**WRONG:** "Performance reviews aren't a structure because they're in contested equilibrium"

**CORRECT:** "Performance reviews ARE a structure—one with high coordination but low legitimacy consensus (contested equilibrium). The structuring is happening. People ARE continuously enacting the pattern, reading cues, forming legitimacy judgments ('this is required compliance theater'), and responding accordingly. The structure contains the contestation as part of its content."

**Relationship to Patterns**

Structures ARE patterns—specifically, patterns that have achieved sufficient coordination and repetition that they guide future behavior. "Structure" and "pattern" are used nearly synonymously when explaining the theory, with "structure" emphasizing the apparent solidity/persistence and "pattern" emphasizing the emergent/enacted nature.

**What Varies Across Structures**

All structures involve continuous enactment. What varies is:

**1. Coordination Level:**
- **Low:** Emerging patterns (high behavioral variance, few people enact)
- **Moderate:** Routines (standardizing, most people enact similarly)
- **High:** Taken-for-granted patterns (minimal variance, automatic enactment)

**2. Legitimacy Consensus:**
- **Low:** Contested (high variance in legitimacy beliefs: SD > 1.5)
- **Moderate:** Routine (moderate consensus: SD 0.8-1.5)
- **High:** Taken-for-granted (very high consensus: SD < 0.8)

**3. Coordination-Legitimacy Alignment:**
- **Aligned:** Coordination and legitimacy move together (typical path)
- **Misaligned:** High coordination, low legitimacy = **contested equilibrium**

**Contested Equilibrium IS a Structure**

Contested equilibrium describes a structure with a particular character:
- High behavioral coordination (everyone does it)
- Low legitimacy consensus (people disagree it's worthwhile)
- Distributed memory HAS formed: "We do X, and it's required compliance theater"
- Structuring IS happening: people enact, read cues, form judgments, respond
- Pattern IS being reproduced through continuous enactment

**The structure exists. It just contains the contestation as part of what's being enacted.**

**Scott's Three Pillars Mapped to ICT**

Institutional Theory (Scott, 1995, 2001) identifies three pillars of institutions. ICT uses the same framework distributed across the six domains:

| Scott's Pillar | ICT Mapping | Measurement |
|----------------|-------------|-------------|
| **Regulative** | Capacity (authority), Motivation (consequences) | Enforcement mechanisms, sanctions |
| **Normative** | Norms & Expectations, Motivation (values) | Social obligations, moral duty |
| **Cultural-Cognitive** | Distributed Memory | Taken-for-granted, legitimacy consensus (SD < 0.8) |

**Structures vary in which pillar dominates:**
- **Contested equilibrium:** Regulative/normative dominant, cultural-cognitive weak
- **Taken-for-granted:** Cultural-cognitive dominant, minimal enforcement needed

**Key Clarifications**

* Structures are not charts, policies, org designs, or stored entities
* Structures are not causes external to action—they ARE coordinated action
* Structures persist through reenactment, not inertia
* When people stop enacting a pattern, the structure dissolves
* **Structures vary in character (coordination level, legitimacy consensus, stability), not in whether they exist**
* **Contested equilibrium is a TYPE of structure, not the absence of structure**
* **Structure (ICT) = Institution (IT): same phenomenon, different vocabulary and emphasis**
* **Structuring operates at ALL levels simultaneously: no scope restriction**
* **Individuals exist within layered, overlapping structures (palimpsest)**
* **Structure and distributed memory are not two separate phenomena—they are two analytically distinguishable aspects of structuration:** Structure is the behavioral aspect (observable coordination), distributed memory is the cognitive aspect (collective learning about legitimacy). The distinction is analytical (for measurement and explanation), not ontological (they're not two things that co-occur).

---

## Distributed Memory

**Canonical Definition**
The cognitive aspect of structuration: what people have collectively learned, through overlapping experiences, about what responses are legitimate, safe, or worthwhile. No single person holds "the structure"—everyone holds fragments, and overlap creates apparent coherence and enables coordination.

**CRITICAL CLARIFICATION: Relationship to Structure**

**Distributed memory and structure are not two separate phenomena.**

They are two analytically distinguishable **aspects** of structuration:

- **Structure** (behavioral aspect): The observable pattern of coordinated action
- **Distributed Memory** (cognitive aspect): The collective learning about legitimacy that guides the pattern

**Analogy:** A wave has amplitude (how high) and frequency (how fast). These are different measurable properties, but they're not two separate phenomena—they're aspects of "wave."

Similarly, structuration has:
- **Behavioral coordination** (coordination level, variance in responses) 
- **Collective learning** (legitimacy consensus, what people have learned)

These are different measurable properties, but they're not two separate phenomena—they're aspects of structuration.

**Why maintain the distinction:**

1. **Contested equilibrium requires it:** High coordination (behavioral aspect) can coexist with low legitimacy consensus (cognitive aspect). Collapsing these would obscure this key insight.

2. **Maps to institutional theory:** Distributed memory corresponds to Scott's cultural-cognitive pillar—one of three bases for institutional persistence, alongside regulative and normative pillars.

3. **Specifies mechanism:** Distributed memory explains HOW patterns persist (through collective learning) and WHAT guides enactment (legitimacy judgments).

4. **Enables precise measurement:** We measure behavioral aspects (variance, coordination) differently from cognitive aspects (legitimacy surveys, consensus).

**The distinction is analytical (for explanation and measurement), not ontological (they're not two things that happen to co-occur).**

**Key Properties**

* **Distributed across individuals** - not stored centrally or in any single person
* **Enacted, not recorded** - exists in continuous enactment of learned responses, not in documents
* **Guides coordination** - shapes what feels legitimate/possible/risky without requiring enforcement
* **Enables behavioral convergence** - overlapping fragments allow people to coordinate without explicit agreement
* **Varies in content** - can be "this is worthwhile" or "this is required compliance theater"

**What Distributed Memory Contains**

Memory is not just "the pattern" but includes interpretive judgments about the pattern:

- **Safety:** Is attempting this action safe here? What are the risks?
- **Acceptability:** Is this action acceptable here? What's considered appropriate?
- **Worthwhileness:** Is this action worthwhile here? Does it matter?
- **Context specificity:** When does this apply? What are the boundary conditions?
- **Implementation knowledge:** How do we actually do this here?

**Example: Performance Reviews**

**Structure (behavioral aspect):**
- 95% of managers complete performance reviews
- High coordination, low variance in completion
- Pattern is continuously enacted

**Distributed Memory (cognitive aspect):**
- Collective learning: "Performance reviews are required compliance theater"
- NOT: "Performance reviews help develop people"
- Safety: "Safe to complete them minimally"
- Acceptability: "Acceptable to treat as checkbox exercise"
- Worthwhileness: "Not worthwhile, but required"

**Both aspects together = contested equilibrium structure**

**How Memory Forms**

Distributed memory develops through:

1. **Direct experience:** People attempt actions and observe what happens
2. **Vicarious observation:** People watch others and note responses
3. **Social transmission:** Stories, explanations, warnings circulate
4. **Cue interpretation:** People read signals across domains and form judgments
5. **Overlapping learning:** Individual fragments align through shared experience

**No central coordination required.** Memory converges (or remains contested) through distributed learning.

**Relationship to Organizational Learning Literature**

**Terminology Note:** Organizational learning literature uses "organizational memory" (Walsh & Ungson, 1991). ICT uses "distributed memory" to emphasize:

1. Memory is not stored in a central location
2. Memory exists in the continuous enactment of learned responses
3. Memory is what people have learned about **legitimacy**, not just about outcomes
4. Memory is the **cognitive aspect** of structuration, complementing the behavioral aspect

**Key difference from organizational learning:**

**Organizational Learning (Levitt & March, 1988):**
- Focus: Outcome-based learning (try → observe results → encode lessons)
- Memory: Encoded in routines as "what works"
- Learning occurs AFTER action is attempted

**ICT's Distributed Memory:**
- Focus: Cue-based learning about legitimacy (observe cues → infer safety/acceptability → decide whether to attempt)
- Memory: Distributed as legitimacy judgments about "what's safe/acceptable/worthwhile"
- Learning occurs BEFORE action is attempted (shapes what gets tried)

Both forms of learning operate simultaneously. ICT complements organizational learning by explaining what determines which actions get attempted in the first place.

**Alternative Terminology**

Some ICT texts use **"structural memory"** to emphasize that memory IS the cognitive aspect of structure (the pattern). 

"Distributed memory" and "structural memory" refer to the same phenomenon—the cognitive aspect of structuration.

"Distributed memory" is preferred because it emphasizes:
- Distribution across individuals (no central storage)
- Distinguished from documents/records (enacted, not recorded)
- Content varies (legitimacy judgments, not just "the pattern")

**Measurement**

Because distributed memory is the cognitive aspect of structuration, it's measured through cognitive/interpretive methods:

**Primary method:** Legitimacy surveys measuring consensus
- Individual judgments (safe? acceptable? worthwhile?)
- Standard deviation across individuals (consensus level)
- SD > 1.5 = contested memory (low consensus)
- SD < 0.8 = convergent memory (high consensus)

**Secondary methods:**
- Interviews: "Why do we do X?" reveals memory content
- Narratives: Stories reveal learned legitimacy judgments
- Explanations to newcomers: What veterans teach reveals memory
- Reaction to questioning: Strong reaction = taken-for-granted memory

**Contested memory indicators:**
- High variance in legitimacy judgments (SD > 1.5)
- Bimodal distributions (some believe X, others believe NOT-X)
- Explanations emphasize "required" not "worthwhile"
- Multiple competing narratives about the same pattern

**Convergent memory indicators:**
- Low variance in legitimacy judgments (SD < 0.8)
- Unimodal distributions (everyone believes similar things)
- Explanations emphasize value, not requirement
- Single coherent narrative

---

## Coordination–Legitimacy Distinction

**Canonical Definition**
A conceptual distinction between behavioral convergence driven by coordination dependencies and interpretive convergence driven by legitimacy.

**Core Insight**
Behavioral stability does not imply legitimacy convergence. Practices can achieve coordination stability (everyone does it) without legitimacy convergence (everyone accepts it).

**Two Tipping Points**

**Coordination Tipping Point:** The threshold at which a practice becomes the cheapest or easiest way to coordinate work, independent of legitimacy. People comply because dependencies, tools, or enforcement make alternatives costly.

**Legitimacy Tipping Point:** The threshold at which a practice becomes taken-for-granted as sensible and appropriate. People defend the practice even when it disadvantages them. Dissent becomes socially weird, not just inconvenient.

---

## Contested Equilibrium

**Canonical Definition**
A stable state in which practices are routinely enacted (coordination has tipped) while legitimacy remains persistently contested (interpretive convergence has not occurred). Behavioral stability without legitimacy convergence.

**CRITICAL CLARIFICATION: Contested Equilibrium IS a Structure**

Contested equilibrium describes a structure with a specific character, NOT the absence of structure.

**Structuring (continuous enactment) IS happening:**
- People read cues (contradictory signals about legitimacy)
- People form legitimacy judgments ("this is required compliance," "this doesn't make sense")
- People respond (enact the practice despite contested legitimacy)
- Responses become new cues for others
- Pattern continues through continuous reenactment

**Distributed memory HAS formed:**
- "We do performance reviews" (behavioral pattern)
- "And it's required compliance theater" (contested meaning)
- **The structure contains the contestation as part of its content**

**What makes contested equilibrium distinctive:**
- High coordination (behavioral convergence)
- Low legitimacy consensus (interpretive divergence)
- Pattern is stable but contested
- Maintained by enforcement/dependencies, not taken-for-granted acceptance

**Core Claim**

Practices can become structurally remembered as routines of compliance before—and even without—becoming legitimate as shared meaning. People learn "this is required" without ever learning "this makes sense." The structure that forms encodes "how to survive this," not "this is right."

**The pattern IS being continuously enacted. The structure exists. It just has a particular character: coordination without interpretive convergence.**

**Independent Discovery and Empirical Support**

The phenomenon ICT calls "contested equilibrium" was independently discovered and empirically demonstrated by institutional theorists:

Haack, Schilke, & Zucker (2021) identified what they term "validity-consensus incongruity"—situations where practices have high **validity** (institutionalized, collective-level perception of appropriateness) but low **consensus** (agreement between evaluators' propriety beliefs). Their key finding: "Validity may hide underlying disagreement."

Their framework distinguishes:
- **Propriety** (individual-level): Personal belief about appropriateness
- **Consensus** (meso-level): Agreement between individual beliefs  
- **Validity** (macro-level): Institutionalized perception of appropriateness

Their empirical research demonstrates that high validity can coexist with low consensus, creating what they call "silenced heterogeneity"—macro-level stability masking micro-level disagreement.

**Relationship Between Frameworks:**

| ICT Term | Haack et al. (2021) Equivalent |
|----------|-------------------------------|
| Individual felt sense of legitimacy | Propriety |
| Distributed memory convergence | Consensus |
| Taken-for-granted status | Validity |
| Contested equilibrium | Validity-consensus incongruity |

**ICT's Distinctive Contribution:**

While Haack et al. (2021) identified the phenomenon at field/organizational level, ICT explains:
1. **How it forms**: Domain misalignment creates contradictory cues that prevent consensus while enforcement sustains coordination
2. **Why it persists**: Cue-based learning continuously reproduces contested interpretations even as behavioral compliance continues
3. **What sustains it**: Structural mechanisms (tools, processes, capacity constraints) maintain coordination independent of legitimacy
4. **When it's stable vs. unstable**: Depends on whether enforcement mechanisms can sustain coordination despite legitimacy challenges

**Citation:**
Haack, P., Schilke, O., & Zucker, L. G. (2021). Legitimacy revisited: Disentangling propriety, validity, and consensus. *Journal of Management Studies, 58*(3), 749-781.

**Why It Matters**

Most organizational theory assumes behavioral stability implies legitimacy ("if people keep doing it, they must accept it"). Both ICT and Haack et al. (2021) demonstrate this is false. Contested equilibrium is not failed institutionalization or a transitional state—it is a predictable and potentially durable structural condition when enforcement mechanisms sustain coordination while cue environments prevent interpretive convergence.

**Examples**

Open office plans, performance reviews, return-to-office mandates, compliance training—widely adopted, persistently contested. These ARE structures being continuously enacted. They just contain the contestation as part of what's being structurated.

---

# CORE (OPERATIONAL) CONCEPTS

These concepts operationalize the core logic and are required for explanation, diagnosis, and empirical work.

---

## Cues

**Canonical Definition**
Observable signals drawn from conditions that indicate what actions are legitimate, risky, or worthwhile.

**Key Property**
Cues gain force through cross-domain consistency. A single cue might be ambiguous, but when multiple cues across multiple domains consistently point in the same direction, they create coherent signals about legitimacy.

**Examples of Cues**

* Leadership attention (what leaders spend time on, ask about, ignore)
* Patterns of reward and punishment (who gets promoted, who gets sidelined)
* Silence around certain topics (what can't be discussed)
* Consistency—or inconsistency—between words and actions
* What gets measured and reviewed
* Who gets resources and support
* How mistakes are treated
* What's celebrated in stories and rituals
* Time allocation (what people actually have capacity for)
* Authority boundaries (who can make which decisions)

---

## Domains of Influence

**Canonical Definition**
Analytically distinct categories of environmental and social cues through which legitimacy is signaled and learned. People interpret legitimacy by reading signals across all domains simultaneously.

**Two Levels**

### Structural / Environmental Domains (5)
Organizational-level domains that can be directly designed, allocated, and controlled by those with authority.

### Collective Domain (1)
Social/peer-level domain that emerges from collective interpretation through social interaction and cannot be directly controlled.

---

### Data & Feedback

**Definition**
What information is visible, reviewed, and acted upon. What gets measured, tracked in performance reviews, discussed in meetings, and made transparent or opaque.

**Three Mechanisms**

* **Structural:** What's measured can be tracked and improved; what's invisible remains unmanaged
* **Signaling:** What gets measured signals importance; what's tracked in reviews signals career impact
* **Cognitive:** What's measured becomes salient; unmeasured phenomena fade from awareness; available metrics determine what questions can be answered

---

### Tools & Processes

**Definition**
Formal and informal mechanisms that shape how work is done. Systems, workflows, approval processes, tooling investments, and the capabilities/constraints tools create.

**Three Mechanisms**

* **Structural:** System capabilities determine what's feasible; approval workflows gate action
* **Signaling:** What receives tooling investment signals priorities; what's automated vs. manual signals value
* **Cognitive:** Tools provide language, categories, and mental models (Jira: "stories/epics/sprints"; kanban: "flow/WIP limits/cycle time"). Tools shape what concepts are available, what breakdowns feel natural, what people can easily visualize.

---

### Capacity

**Definition**
What people have the time, authority, energy, and structural position to accomplish. How time and authority are allocated, what competing demands exist, who can say "no" to what.

**Three Mechanisms**

* **Structural:** Time, authority, and resources determine what's structurally possible
* **Signaling:** How time and authority are allocated reveals actual priorities, often contradicting verbal commitments. Tolerance of capacity constraints signals true values.
* **Cognitive:** Chronic overload trains people to think short-term; long-horizon planning feels unrealistic. Never experiencing slack makes slack-dependent activities (reflection, exploration, relationship building) cognitively unavailable. Authority boundaries shape what feels "within scope" vs. "not my domain."

**Special Note**
Capacity can function as a gating condition: when Capacity constraints are severe (zero available time, absolute authority prohibition), consistency across all other domains cannot produce behavioral enactment.

---

### Skills & Knowledge

**Definition**
What the environment makes learnable, transferable, and usable. What training is provided, what expertise is developed, what knowledge is accessible.

**Three Mechanisms**

* **Structural:** What people know how to do determines accessible options
* **Signaling:** What training is funded signals where the organization expects people to develop
* **Cognitive:** If you don't know technique X exists, you can't recognize situations where X would help. Training in particular methodologies shapes what problems are visible. Professional socialization shapes what feels like "real work" vs. auxiliary activity.

---

### Motivation & Values

**Definition**
What the system rewards, discourages, or makes meaningful. What leads to advancement, bonuses, recognition, or punishment.

**Three Mechanisms**

* **Structural:** Consequences shape which actions feel worth attempting
* **Signaling:** What leads to advancement reveals true values, regardless of stated culture
* **Cognitive:** Reward structures shape what feels like "winning" vs. "losing." What's celebrated in stories shapes aspirational identity. You see what you're primed to care about.

---
### Norms & Expectations

**Definition**
What behavior is taken for granted, praised, ignored, or quietly penalized. What "people like me" do. What stories circulate. Informal signals about what's socially acceptable, identity-based expectations, and informal sanctions.

**Key Difference from Structural Domains**
Norms & Expectations operates fundamentally differently from the five structural domains:

**Relationship to "Norms as Conditions":**

Individual norm enactments (stories told, reactions observed, sanctions applied) are **conditions**—discrete, observable instances that people encounter and interpret.

The **Norms & Expectations domain** is the **emergent collective pattern** formed when many such instances converge. It represents what has become taken-for-granted through distributed learning.

People don't observe "the Norms & Expectations domain" directly—they observe discrete norm enactments (conditions), interpret those instances, and through overlapping experience, a collective pattern emerges.

**The Relationship:**

**Observable norm enactments** (conditions) → People interpret these instances → **Collective pattern emerges** (Norms & Expectations domain)

**Analogy:**
* Individual raindrops = observable conditions (you can see/feel each one)
* Weather pattern = domain (the emergent phenomenon when many raindrops form a coherent system)

**Recursive Function**

1. **As observable input:** Peer signals, stories, identity markers that individuals encounter
2. **As emergent process:** Collective sense-making as people compare experiences
3. **As outcome:** The stabilized pattern of distributed memory when interpretations converge
4. **As input again:** That pattern becomes a condition newcomers encounter

**Unlike structural domains, Norms:**

Organizations cannot design Norms directly, only influence it indirectly by shaping the structural domains from which normative patterns emerge. In institutional theory terms, Norms & Expectations is where legitimacy ultimately resides. When practices achieve "taken-for-granted" status, that taken-for-grantedness lives in Norms & Expectations.

**Examples**

* "Remember what happened to Jamie when they questioned the timeline?" (story that teaches risk)
* "Everyone leaves at 7pm but nobody talks about it" (unspoken social norm)
* "Real engineers here solve problems, they don't raise problems" (identity-based expectation)
* "People who use all their vacation are seen as uncommitted" (informal sanction)

---

## Change

**Canonical Definition**
A shift in conditions—particularly legitimacy cues across domains—combined with coordinated enactment of new responses that, through repetition, create new distributed memory.

**Not Change**
* Declaration of goals, attitudes, or desired end states
* Announcement of new values
* Training alone
* Leadership messaging alone

**Change Requirements**
1. Conditions shift to make new responses legitimate
2. Enough people enact the new response that it becomes coordinated
3. The new pattern gets repeated enough that it becomes learned
4. Distributed memory now encodes the new pattern as "how we do things"

**Two Types of Change Failure**

* **Type 1 (Conditions don't actually change):** Leaders announce new values but cues across domains still reinforce old patterns. Result: Brief compliance followed by reversion.
* **Type 2 (Coordination doesn't emerge):** Conditions shift but people don't enact new responses at sufficient scale/consistency. Result: Scattered adoption, no pattern formation, eventual abandonment.

---

# SUPPORTING CONCEPTS (ICT-OWNED)

These concepts refine mechanisms and implications but are not identity-defining.

---

## Three Domain Mechanisms

ICT identifies three mechanisms through which structural domains shape patterns:

### Structural Mechanism

**Definition**
How domains enable or constrain action through allocation of tools, resources, authority, and time. What's structurally possible or impossible given system design.

---

### Signaling Mechanism

**Definition**
How domains reveal priorities and legitimacy through investment, enforcement, attention, and tolerance. What allocation patterns signal about what truly matters.

**Key Insight**
Allocation reveals actual priorities, often contradicting verbal commitments. What gets resources/time/attention signals value more powerfully than what gets words.

---

### Cognitive Mechanism

**Definition**
How domains shape what is thinkable by providing language, categories, and mental models. What concepts are available, what breakdowns feel natural, what people can easily visualize or imagine.

**Why It Matters**
Changing structural domains doesn't just change what's possible and what's valued—it changes what's thinkable. Tools shape language (Jira vs. kanban creates different concepts). Metrics shape what counts as evidence. Capacity shapes time horizons. Contradictory domains create cognitive dissonance beyond simple mixed signals.

---

## Cue-Based Learning

**Definition**
Learning that occurs through interpretation of environmental cues about legitimacy prior to action. People read cues across domains, infer what's safe/legitimate, and respond accordingly—shaping what gets attempted, not just what gets retained after trial.

**Contrast with Outcome-Based Learning**
Organizational learning literature focuses on outcome-based learning: try actions → observe results → encode lessons. ICT focuses on cue-based learning: observe cues → infer legitimacy → don't attempt actions that seem illegitimate.

**Key Difference**
ICT explains learning that occurs **before action is attempted**. This explains why some practices never get tried despite potential benefits (legitimacy cues prevent trial) and why others persist despite poor performance (legitimacy cues remain supportive).

---

## Domain Alignment

**Definition**
The degree to which cues across domains consistently signal the same legitimacy judgment.

**When domains align:** Cues across all domains point in the same direction, creating clear signals about what's legitimate.

**When domains contradict:** Cues send conflicting signals. Result: Confusion, scattered attempts, no pattern formation.

**Critical Threshold**
Legitimacy convergence likely requires consistency in at least four domains, including Norms & Expectations.

---

## Coordination Stability

**Definition**
The durability of behavioral enactment produced by coordination dependencies or enforcement, independent of legitimacy.

**Mechanism**
Practices become coordination-stable when:
* Tools/processes become mandatory to get work done
* Dependencies assume participation
* Opt-out becomes costly (friction, delays, exclusion from information/decisions)

**Key Distinction**
Coordination stability ≠ legitimacy. High coordination stability can coexist with persistently contested legitimacy (contested equilibrium).

---

## Stewardship of Conditions

**Definition**
The capacity of some actors to shape the conditions others respond to, without being able to impose legitimacy directly.

**What Stewards Can Do**

* Alter what's measured and reviewed (Data & Feedback)
* Change tool capabilities and workflows (Tools & Processes)
* Allocate time, authority, and resources (Capacity)
* Fund training and knowledge development (Skills & Knowledge)
* Connect actions to consequences (Motivation & Values)

**What Stewards Cannot Do**

* Mandate legitimacy (even powerful actors cannot simply impose taken-for-grantedness)
* Control Norms & Expectations directly (can only influence indirectly)
* Guarantee coordination or legitimacy convergence (people still interpret and respond)

**Power's Role**
Power matters most in determining:
* What gets monitored and enforced (affecting coordination tipping points)
* What becomes visible or invisible (affecting cue availability)
* Whose interpretations get amplified or suppressed (affecting coordination around which pattern)

But power cannot directly create taken-for-grantedness. That requires coordinated enactment and distributed learning over time.

---

## Empirical Measurement of Structuration

**Purpose**
ICT adopts a process ontology (structures exist only in continuous enactment) but must provide empirical methods for measuring degree of structuration at any moment.

**Solution: Property Variable + Process Framework**

Following Tolbert & Zucker (1996): "Institutionalization is both a property variable and a process."

Applied to ICT: **Structuration is both a property variable (measurable degree at a moment) and a process (continuous enactment over time).**

This resolves the apparent paradox:
- **YES:** Structures exist only through continuous enactment (process ontology)
- **AND:** We can measure degree of structuration empirically (property variable)

**What We Measure**

NOT: "Is this a structure?" (binary)
BUT: "To what degree has this pattern become structurated?" (continuous variable along multiple dimensions)

**Dimensions of Structuration**

All continuous enactment IS structuring. What varies is CHARACTER:

1. **Coordination Level** (behavioral convergence)
   - Low: High variance in responses, few people enact similarly
   - High: Minimal variance, nearly everyone responds the same way

2. **Legitimacy Consensus** (interpretive convergence)
   - Low: High variance in beliefs (SD > 1.5)
   - High: Very high consensus (SD < 0.8)

3. **Stability** (resistance to change)
   - Low: Easily disrupted, doesn't self-restore
   - High: Resistant to disruption, automatically restores

4. **Taken-for-Grantedness** (cognitive pillar strength)
   - Low: Requires deliberation, needs explanation
   - High: Automatic, questioning seems strange

**Framework: Three Stages Plus Contested Equilibrium**

Based on Tolbert & Zucker (1996), all stages involve structuring (continuous enactment). They differ in character:

**Stage 1: Pre-Institutionalization (Habitualization)**
- Coordination: Low (high behavioral variance)
- Consensus: Low (contested, SD > 1.5)
- Stability: Low (easily disrupted)
- Taken-for-grantedness: Low (requires deliberation)

**Stage 2: Semi-Institutionalization (Objectification)**
- Coordination: Moderate (standardizing)
- Consensus: Moderate (SD 0.8-1.5)
- Stability: Moderate (requires monitoring)
- Taken-for-grantedness: Moderate (becoming routine)

**Stage 3: Full Institutionalization (Sedimentation)**
- Coordination: High (minimal variance)
- Consensus: High (SD < 0.8)
- Stability: High (self-perpetuating)
- Taken-for-grantedness: High (automatic, unquestioned)

**Contested Equilibrium (Coordination-Legitimacy Misalignment)**
- Coordination: High (everyone does it)
- Consensus: Low (contested, SD > 1.5)
- Stability: Moderate to high (enforcement-maintained)
- Taken-for-grantedness: Low (requires justification: "it's required")

**Measurement Methods**

ICT uses measurement methods from institutional theory (same phenomenon, same methods):

**METHOD 1: Legitimacy Surveys (Multi-Level)**

Sources: Haack, Schilke, & Zucker (2021); Tost (2011)

**Individual Level (Propriety):**
Survey items (1-7 scale):
- "Attempting [practice] is safe here"
- "Attempting [practice] is acceptable here"
- "Attempting [practice] is worthwhile here"

**Calculate consensus:**
Standard deviation across respondents
- SD > 1.5 = Contested (low consensus)
- SD 0.8-1.5 = Moderate consensus
- SD < 0.8 = High consensus (taken-for-granted)

**Collective Level (Consensus):**
- Agreement between individual beliefs
- Variance decomposition (within vs. between groups)

**Institutional Level (Validity):**
- Leadership endorsement
- Policy inclusion
- Widespread adoption

**METHOD 2: Behavioral Variance Analysis**

Observe responses to similar conditions:
- How many different response types occur?
- What's the variance in implementation?
- How predictable is the response?

Track over time:
- High variance → Low coordination (emerging)
- Decreasing variance → Increasing coordination (routinizing)
- Minimal variance → High coordination (taken-for-granted)

Measures:
- Coefficient of variation in behaviors
- Inter-rater reliability of "what we do here"
- Number of distinct response types

**METHOD 3: Effort Tracking (Deliberation → Automatic)**

Measure cognitive/social effort required:

Emerging pattern indicators:
- Requires explicit deliberation
- Needs detailed explanation to newcomers
- Justification frequently demanded
- Active debate about whether/how

Taken-for-granted indicators:
- Automatic (no deliberation)
- No explanation needed ("obviously")
- Justification seems weird
- No debate (questioning is strange)

Measures:
- Time-to-decision
- Length of explanations to new members
- Frequency of debates

**METHOD 4: Disruption Resistance Tests**

Introduce disruption and measure:
- How easily does pattern break?
- How quickly does it restore?
- How much resistance to disruption?

Test scenarios:
- Remove enforcement
- Introduce contradictory cues
- Change championing leadership
- Reduce supporting resources

Emerging: Easy to disrupt, doesn't self-restore
Taken-for-granted: Very difficult to disrupt, automatic restoration

**METHOD 5: Survival Across Turnover Studies**

Track pattern across member changes:

Emerging pattern:
- Doesn't survive turnover
- Dies when champions leave

Taken-for-granted:
- Survives complete turnover
- New members absorb automatically
- Self-perpetuating

**METHOD 6: Domain Cue Consistency Analysis**

ICT-specific contribution: Measure alignment across six domains

For each domain, assess whether cues support the pattern (0-2 scale):
- Capacity: Resources allocated? Time available?
- Tools: Systems encode pattern?
- Data: Metrics measure this?
- Skills: Training provided?
- Motivation: Consequences aligned?
- Norms: Stories reinforce?

Calculate consistency score:
- Sum / Maximum = % consistency
- < 50% = Low consistency (emerging/contested)
- 50-80% = Moderate consistency (routinizing)
- > 80% = High consistency (likely taken-for-granted)

**Domain consistency predicts:**
- Low consistency + High coordination = Contested equilibrium (enforcement)
- High consistency + Low coordination = Emerging consensus (not yet tipped)
- High consistency + High coordination = Taken-for-granted (aligned)

**Integrated Measurement Strategy**

**Minimum viable (practical research):**
1. Legitimacy survey (consensus)
2. Behavioral observation (coordination)
3. Domain cue assessment (consistency)

**Comprehensive (rigorous research):**
1. Multi-level legitimacy survey
2. Behavioral variance analysis over time
3. Effort tracking (deliberation vs. automatic)
4. Disruption tests (resistance and restoration)
5. Survival studies (across turnover)
6. Domain cue consistency (alignment)
7. Longitudinal diffusion (if applicable)

**Contested Equilibrium Detection**

Specific pattern of measurements indicating contested equilibrium:
- HIGH coordination (>80% compliance)
- LOW consensus (SD > 1.5)
- MODERATE to HIGH stability (survives but requires enforcement)
- LOW domain consistency in cultural-cognitive areas
- HIGH domain consistency in regulative areas
- Pattern disrupts when enforcement removed

### Addressing Social Desirability Bias

**The Challenge**

Legitimacy surveys face a significant methodological challenge: social desirability bias. People may report beliefs they think are expected or acceptable rather than their actual judgments, particularly when:
- Leadership actively promotes the practice
- There's social pressure to appear supportive
- Dissent seems risky or career-limiting
- Organizational culture punishes questioning

**Example:** Everyone publicly says "performance reviews help develop people" while privately believing "they're compliance theater." Surveys show false consensus, masking contested equilibrium.

**Mitigation Strategies**

**STRATEGY 1: Triangulation (Primary Defense)**

Never rely on self-report surveys alone. Require convergence across multiple methods:

**If contested equilibrium exists, we should see:**
- Behavioral indicators (effort minimization, workarounds)
- AND survey indicators (low consensus OR high variance)
- AND domain indicators (regulative strong, cultural-cognitive weak)
- AND disruption indicators (pattern collapses without enforcement)

**If these converge → high confidence**
**If they diverge → investigate why (possible social desirability bias)**

**STRATEGY 2: Anonymous/Confidential Administration**

Reduce pressure to give "correct" answers:
- Third-party administration (not leadership)
- Aggregate reporting only (no individual identification)
- Explicit confidentiality assurances
- Separate from performance evaluation processes

**STRATEGY 3: Indirect Measurement**

Ask about collective belief rather than personal belief:

**Instead of:** "Do you believe performance reviews are worthwhile?" (direct, subject to bias)
**Ask:** "Do most people here believe performance reviews are worthwhile?" (indirect, more honest)

Research shows people are more honest about "what others think" than about their own views when social pressure exists. Aggregate responses reveal collective belief patterns while reducing individual pressure to conform.

**STRATEGY 4: Behavioral Proxies (Most Robust)**

Prioritize observable behaviors that indicate legitimacy without requiring self-reports. See next section for specific indicators.

**STRATEGY 5: Safe Space Inquiry**

Create conditions where honest responses are more likely:
- Exit interviews (departing members less constrained)
- One-on-one confidential conversations
- Off-site/informal settings
- Questions framed as helping understand, not judging

**STRATEGY 6: Variance as Signal**

High variance itself can indicate contested legitimacy even if means appear moderate:
- Bimodal distributions (some strongly agree, others strongly disagree)
- Large standard deviations (SD > 1.5)
- Different responses in different subgroups

**Even if social desirability pulls responses toward "acceptable" range, variance reveals disagreement.**

**Recommended Approach**

**Behavioral indicators as PRIMARY evidence** (least subject to bias)
**Surveys as SECONDARY/TRIANGULATION** (with bias mitigation)

If behavioral indicators suggest contested equilibrium but surveys show consensus:
→ Suspect social desirability bias
→ Use indirect measurement and safe space inquiry
→ Examine variance and subgroup differences
→ Run disruption tests

### Observable Behavioral Indicators of Contested vs. Taken-for-Granted Legitimacy

**The Value of Behavioral Indicators**

Observable behaviors provide evidence of legitimacy that doesn't rely on self-reports and thus avoids social desirability bias. These indicators can be systematically observed, coded, and measured.

**CONTESTED EQUILIBRIUM - Observable Behavioral Indicators**

When coordination is high but legitimacy is contested, look for:

**1. Minimal Compliance**
- People do just enough to satisfy requirements
- "Checkbox" completion without substance
- No voluntary effort beyond minimum
- High completion rates but low quality/engagement

**Observable:** Completion metrics vs. quality metrics diverge

**2. Workarounds and Creative Avoidance**
- People find ways to technically comply while avoiding substance
- "Gaming" the system
- Clever ways to minimize effort while appearing compliant
- Parallel informal systems that actually do the work

**Observable:** Gap between formal process and actual practice

**3. Rapid Abandonment When Enforcement Weakens**
- Participation drops sharply if monitoring decreases
- Pattern doesn't self-sustain
- People stop immediately when "no one is watching"
- Requires continuous active enforcement

**Observable:** Participation rate tracks enforcement intensity

**4. No Voluntary Defense**
- When practice is criticized, no one defends it
- People remain silent or nod in agreement with criticism
- No champions emerge naturally
- Absence of advocacy or protection

**Observable:** Response patterns when practice is questioned

**5. "Required" Explanations**
- When explaining to newcomers: "You have to do this"
- Not: "This helps us because..."
- Emphasis on compliance, not value
- Justification based on rules/consequences, not benefits

**Observable:** Language patterns in explanations (code for "required" vs. "worthwhile" framing)

**6. Repeated Newcomer Questions**
- New members repeatedly ask "Why do we do this?"
- The question never stops being asked
- Each cohort questions it anew
- Never becomes self-evident

**Observable:** Frequency and persistence of "why" questions over time

**7. Private vs. Public Narrative Divergence**
- Different stories in formal vs. informal settings
- Public compliance, private cynicism
- What's said in meetings ≠ what's said in hallway
- Safe spaces reveal different narrative

**Observable:** Compare public statements to private conversations (where accessible)

**8. Mockery and Cynicism**
- Jokes about the practice
- Eye-rolls when it's mentioned
- Sarcasm in discussions
- Cultural markers of disbelief (inside jokes, knowing looks)

**Observable:** Tone, humor patterns, non-verbal cues in meetings

**9. High Variance in Implementation Quality**
- Everyone complies (high coordination)
- But implementation varies wildly (low standardization)
- Some go through motions, others do it substantively
- Completion ≠ quality

**Observable:** Coefficient of variation in quality metrics vs. completion metrics

**10. Differential Adoption Across Subgroups**
- Some groups/teams comply fully
- Others resist or minimize
- Pattern: those closer to enforcement comply, those farther resist
- Spatial/hierarchical variance in adoption

**Observable:** Adoption rates across organizational units

**TAKEN-FOR-GRANTED - Observable Behavioral Indicators**

When coordination AND legitimacy are high, look for:

**1. Voluntary Adoption Beyond Minimum**
- People do more than required
- Extensions and innovations
- Voluntary refinements
- Goes beyond compliance to contribution

**Observable:** Effort/quality exceeds requirements

**2. Pattern Continues Without Enforcement**
- Participation doesn't drop when monitoring decreases
- Self-sustaining
- Automatic continuation
- No active enforcement needed

**Observable:** Stability across varying enforcement conditions

**3. Active Defense When Questioned**
- People defend practice when criticized
- Champions emerge naturally
- Arguments for value provided spontaneously
- Resistance to removal

**Observable:** Response patterns when practice is threatened

**4. "Value" Explanations**
- When explaining to newcomers: "This helps us by..."
- Emphasis on benefits and purpose
- Justification based on outcomes, not rules
- Natural articulation of value

**Observable:** Language patterns in explanations (code for value framing)

**5. Newcomers Stop Questioning**
- Initial "why do we do this?" questions decline
- Becomes self-evident through participation
- Each cohort accepts it quickly
- Questioning seems naive after socialization

**Observable:** Decline in "why" questions over tenure

**6. Public-Private Narrative Alignment**
- Same story in all settings
- Consistent articulation of value
- No cynicism in informal spaces
- Coherent narrative across contexts

**Observable:** Narrative consistency across settings

**7. Genuine Enthusiasm**
- Positive affect when discussing
- Pride in doing it well
- Voluntary sharing of best practices
- Cultural markers of belief (celebration, recognition)

**Observable:** Tone, affect, voluntary engagement

**8. Low Variance in Implementation Quality**
- Not just high completion (coordination)
- But also standardized quality (shared understanding)
- Convergent implementation
- Mutual intelligibility

**Observable:** Low coefficient of variation in both completion AND quality

**9. Automatic Restoration After Disruption**
- If disrupted, pattern quickly restores
- People actively recreate it
- Self-healing system
- Strong pull back to pattern

**Observable:** Restoration speed after temporary disruption

**10. Uniform Adoption Across Subgroups**
- Consistent adoption across units
- No spatial/hierarchical variance
- Transcends boundaries
- Universal enactment

**Observable:** Low variance across organizational units

**Systematic Observation Methods**

**Ethnographic Observation:**
- Attend meetings, note language patterns
- Observe informal interactions
- Record jokes, cynicism, enthusiasm
- Document explanations to newcomers

**Archival Analysis:**
- Email/Slack patterns (where legally/ethically accessible)
- Meeting notes and agendas
- Training materials and explanations
- Completion vs. quality metrics

**Interview Coding:**
- Code for "required" vs. "worthwhile" framing
- Track frequency of "why" questions
- Note presence/absence of defense
- Compare public and private narratives

**Metrics Analysis:**
- Participation rates over time
- Quality variance across units
- Correlation with enforcement intensity
- Restoration speed after disruption

**Coding Scheme Example:**

For each instance of practice discussion:
- Context: Public meeting / Private conversation / Explanation to newcomer
- Framing: Required (0) / Mixed (1) / Worthwhile (2)
- Affect: Cynical (0) / Neutral (1) / Enthusiastic (2)
- Defense: None (0) / Weak (1) / Active (2)
- Quality: Minimal (0) / Adequate (1) / Excellent (2)

Aggregate scores reveal patterns without relying on direct legitimacy questions.

### Measurement Thresholds: Current Heuristics and Future Empirical Work

**Current Status**

The measurement thresholds specified in ICT (80% for coordination, SD thresholds for legitimacy consensus) are **heuristic operational definitions** based on theoretical reasoning and initial application experience. They provide practical guidance for empirical work but **require systematic empirical validation** across contexts.

**Coordination Threshold (Currently: 80%)**

**Theoretical Basis:**
Coordination stabilizes when a critical mass of actors participate, making opt-out costly due to:
- Network effects (value increases with adoption)
- Tool/process dependencies (required to get work done)
- Social pressure (deviance becomes notable)
- Switching costs (alternative approaches become expensive)

**Current Heuristic:** 80%+ participation indicates coordination has tipped

**Rationale:** 
- At 80%, pattern is dominant enough that opting out creates friction
- Minority who don't participate face coordination costs
- Tools and dependencies assume majority adoption
- Social norm establishes (5:1 ratio of participants to non-participants)

**Context Sensitivity:**

The coordination threshold likely varies based on:

**Network Density:**
- High interdependence → Lower threshold (50-60% may suffice)
- Low interdependence → Higher threshold (90%+ may be needed)

**Enforcement Strength:**
- Strong enforcement → Pattern persists at lower voluntary adoption
- Weak enforcement → Higher threshold needed for self-sustaining coordination

**Switching Costs:**
- High costs (locked-in tools, dependencies) → Lower threshold
- Low costs (easy alternatives) → Higher threshold

**Task Criticality:**
- Critical path work → Lower threshold (can't work without it)
- Peripheral work → Higher threshold

**Future Empirical Work Needed:**
1. Systematic measurement of when coordination becomes self-sustaining across contexts
2. Identification of context factors that shift threshold
3. Development of context-specific threshold guidance
4. Longitudinal studies tracking coordination emergence

**Legitimacy Consensus Thresholds (Currently: SD > 1.5 = contested, SD < 0.8 = convergent)**

**Theoretical Basis:**
Standard deviation on a 7-point scale indicates spread of beliefs:
- SD > 1.5 suggests responses spanning 3+ scale points (fundamental disagreement)
- SD < 0.8 suggests responses clustered within 2 scale points (strong agreement)
- SD 0.8-1.5 suggests moderate consensus

**Current Heuristic:**
- SD < 0.8 = Convergent (taken-for-granted)
- SD 0.8-1.5 = Moderate consensus (routine)
- SD > 1.5 = Contested (low consensus)

**Rationale:**
- At SD > 1.5 on 7-point scale, some respondents strongly agree (6-7) while others disagree (3-4 or lower)
- This represents genuinely contested beliefs, not just minor variation
- At SD < 0.8, nearly everyone responds within narrow range (e.g., all 5-6)
- This represents taken-for-granted consensus

**Additional Consideration: Bimodal Distributions**

Beyond SD, distribution shape matters:
- Bimodal (two peaks) = contested even if mean appears moderate
- Unimodal (single peak) = consensus around that level

**Future Empirical Work Needed:**
1. Validation of SD thresholds against behavioral outcomes
2. Investigation of distribution shapes (bimodal vs. unimodal)
3. Cultural and contextual factors affecting thresholds
4. Relationship between legitimacy consensus and coordination stability
5. Longitudinal tracking of how SD changes as patterns institutionalize

**Multi-Dimensional Consensus**

Remember that legitimacy has three dimensions (Tost, 2011):
- Safe
- Acceptable  
- Worthwhile

Pattern may show consensus on one dimension but not others:
- High consensus on "safe" (SD < 0.8)
- Low consensus on "worthwhile" (SD > 1.5)

**This is contested equilibrium:** Agreement it's required/safe, disagreement about value.

**Guidance for Researchers**

**Until systematic empirical validation:**

1. **Use current thresholds as starting points** (80% coordination, SD thresholds)
2. **Document context factors** that may affect thresholds in your setting
3. **Report actual values** (don't just categorize as "high/low")
4. **Triangulate** with behavioral indicators (don't rely solely on thresholds)
5. **Examine distributions** (not just means and SDs)
6. **Be transparent** about threshold decisions and rationale

**When thresholds seem inappropriate for your context:**
- Justify alternative thresholds theoretically
- Document context factors that warrant adjustment
- Report both standard and adjusted thresholds
- Contribute to empirical literature on threshold variation

**Long-term Goal**

Develop empirically validated, context-specific threshold guidance through:
- Systematic studies across organizational types
- Meta-analysis of threshold effects
- Machine learning approaches to threshold optimization
- Practitioner validation of what "tipped" feels like
- Longitudinal tracking of threshold crossing

**Current status:** Operational heuristics based on theoretical reasoning
**Future status:** Empirically validated guidelines with context-specific adjustment factors

**Sources**

Core measurement framework:
- Tolbert, P. S., & Zucker, L. G. (1996). The institutionalization of institutional theory.
- Tolbert, P. S., & Zucker, L. G. (1983). Institutional sources of change in the formal structure of organizations.
- Haack, P., Schilke, O., & Zucker, L. G. (2021). Legitimacy revisited: Disentangling propriety, validity, and consensus.
- Scott, W. R. (2001). Institutions and Organizations.
- Tost, L. P. (2011). An integrative model of legitimacy judgments.

---

## Human Systems

**Definition**
Collectives in which coordination and stability emerge through ongoing interpretation and response rather than through direct control or compliance.

**Key Properties**

* Interpretive (people actively make sense of their environment)
* Agentic (people choose how to respond, even when constrained)
* Emergent (coordination arises from distributed responses, not central direction)

**Scope**
ICT applies to human systems where interpretation, legitimacy, and learning operate over time. Does not apply to purely mechanical systems or contexts where interpretation is impossible.

---

# IMPORTED SUPPORTING CONCEPTS (NON-ICT)

These concepts are **explicitly borrowed**, bounded, and not owned by ICT.
ICT uses specific mechanisms or findings but does not claim the full theoretical apparatus.

---

## Institutional Legitimacy

**Source:** Meyer & Rowan (1977); DiMaggio & Powell (1983)

**Used by ICT**
Legitimacy as a driver of behavior independent of technical efficiency. The insight that organizations adopt practices to gain legitimacy, not just to improve performance.

**Not Claimed by ICT**

* Field-level diffusion mechanisms (how practices spread across organizations)
* Isomorphism explanations (why organizations come to look alike)
* Institutional entrepreneurship (how institutional change originates)

**Boundary**
ICT operates within organizations; institutional theory operates across organizational fields. Field-level phenomena function as conditions that people within organizations interpret and respond to, but ICT does not explain how those field-level phenomena emerge.

---

## Structuration (Duality of Structure)

**Source:** Giddens (1984)

**Used by ICT**
Structure as both medium and outcome of action. The recursive relationship between structure and agency. The insight that structures don't exist independently but are continuously produced through action.

**Not Claimed by ICT**

* Full ontological system of structuration theory
* Specific typology of structures (signification, domination, legitimation)
* Theory of time-space distanciation

**Boundary**
ICT adopts structuration's process ontology (structure as continuous doing) while operationalizing it through specific mechanisms (domains, cues, legitimacy learning) for within-organization analysis.

---

## Bounded Agency Theory

**Source:** Evans (2007, 2017); Biesta & Tedder (2007)

**Used by ICT**

* Agency as individual, not collective
* Agency as bounded by structural conditions (not unlimited freedom)
* Agency as process shaped by past experiences, present context, perceived futures
* Perceived possibility space ("personal horizons") shaped by structural resources
* Temporal horizon ("shadow of the future") affecting risk assessment
* Variation in agency based on position, resources, and interpretation

**What ICT Directly Adopts**

ICT uses Evans' bounded agency framework to specify how agency operates within structural constraints:

**Core principle:** "Agency is a socially situated process, shaped by the experiences of the past, the chances present in the current moment and the perceptions of possible futures" (Evans, 2007)

**Key mechanisms:**
- **Structural conditions constrain the RANGE** of responses that feel possible/safe/worthwhile
- **Agency determines WHICH response** within that constrained range
- **Different positions provide different constraints** and resources → different possibility spaces
- **Change emerges from aggregated agency** when structural room exists and responses coordinate

**ICT's application to organizational context:**
- Six domains provide specific structural constraints (what bounds agency)
- Cue-based interpretation shapes perceived possibilities (what enables variation)
- Distributed memory encodes which responses are legitimate (structural context for agency)
- Aggregated individual responses reproduce or transform patterns (agency → structure change)

**What ICT Extends**

1. **Specifies constraint sources:** Six organizational domains that bound agency
2. **Cue-based possibility perception:** How people learn what's possible through interpretation
3. **Domain consistency effects:** Contradictory cues create wider variation in agency; aligned cues narrow it
4. **Aggregation mechanism:** How individual bounded agency aggregates to pattern change
5. **Legitimacy as mediator:** Agency operates through legitimacy assessment, not just feasibility

**Not Claimed by ICT**

* Life course development across transitions
* Educational choice and career pathways
* Identity formation through agency
* Broader societal structures beyond organizational contexts

**Boundary**

Bounded agency theory explains how individual agency operates within structural constraints across life domains. ICT applies this framework specifically to organizational behavior: structural conditions (from six domains) constrain perceived possibilities, individual agency produces variation within those constraints, and aggregated responses reproduce or transform organizational patterns. ICT specifies the organizational mechanisms (cue-based interpretation, legitimacy assessment, distributed memory) through which bounded agency operates in work settings.

**Citations:**
- Evans, K. (2007). Concepts of bounded agency in education, work, and the personal lives of young adults. *International Journal of Psychology, 42*(2), 85-93.
- Evans, K. (2017). Bounded agency in professional lives. In M. Goller & S. Paloniemi (Eds.), *Agency at Work: An Agentic Perspective on Professional Learning and Development* (pp. 17-36). Springer.
- Biesta, G., & Tedder, M. (2007). Agency and learning in the life course: Towards an ecological perspective. *Studies in the Education of Adults, 39*(2), 132-149.

---

## Sensemaking

**Source:** Weick (1995)

**Used by ICT**
Interpretation as socially situated. The insight that people make sense of equivocal cues through ongoing interaction and that meaning emerges through retrospection and enactment.

**Not Claimed by ICT**

* Retrospection as primary mechanism (ICT focuses on prospective legitimacy assessment)
* Ambiguity/equivocality as central problem (ICT focuses on cue consistency/inconsistency)
* Sensemaking as primarily occurring during disruption (ICT focuses on ongoing interpretation)

**Boundary**
Sensemaking informs ICT's concept of interpretation but ICT adds legitimacy as the specific type of meaning being made and distributed memory as the stabilizing mechanism.

---

## Multi-Level Legitimacy Theory

**Source:** Haack, Schilke, & Zucker (2021)

**Used by ICT**

* Three-level framework: propriety (individual), consensus (collective), validity (institutional)
* Empirical operationalization of legitimacy at each level
* Discovery that validity can hide underlying disagreement (validity-consensus incongruity)
* Measurement approaches for each level
* Insight that macro-level stability can mask micro-level heterogeneity

**What ICT Directly Adopts**

ICT's phenomenological/relational/institutional ontology of legitimacy maps directly onto Haack et al.'s propriety/consensus/validity framework:
- ICT's phenomenological level = Haack et al.'s propriety (individual belief)
- ICT's relational level = Haack et al.'s consensus (agreement through interaction)
- ICT's institutional level = Haack et al.'s validity (taken-for-granted status)

ICT adopts their measurement approaches:
- Individual surveys for phenomenological legitimacy
- Variance/consensus metrics for relational convergence
- Endorsement/authorization indicators for institutional validity

**What ICT Extends**

1. **Causal mechanisms**: ICT specifies how validity-consensus incongruity forms (domain misalignment) and persists (cue-based learning)
2. **Within-organization focus**: Haack et al. operate at field level; ICT operates within organizations
3. **Legitimacy dimensions**: ICT measures safe/acceptable/worthwhile (not just "appropriate")
4. **Cue sources**: ICT specifies which domains signal legitimacy
5. **Coordination distinction**: ICT distinguishes coordination stability from legitimacy convergence

**Not Claimed by ICT**

* Field-level legitimacy processes
* Institutional change originating from legitimacy disclosure
* Political/social movement applications
* Full micro-foundations research program

**Boundary**

Haack et al. (2021) discovered validity-consensus incongruity (contested equilibrium) at the field/organizational level and demonstrated it empirically. ICT explains the within-organization mechanisms that create and sustain this phenomenon, specifying how domain misalignment prevents consensus while structural mechanisms maintain coordination.

**Citation:**
Haack, P., Schilke, O., & Zucker, L. G. (2021). Legitimacy revisited: Disentangling propriety, validity, and consensus. *Journal of Management Studies, 58*(3), 749-781.

---

## Legitimacy Judgment Process

**Source:** Tost (2011)

**Used by ICT**

* Two processing modes: Passive/heuristic (low effort) and Evaluative/systematic (high effort)
* Three legitimacy dimensions: Instrumental, relational, moral (ICT translates as safe, acceptable, worthwhile)
* Cue-based judgment formation process
* Insight that most organizational legitimacy judgments occur in passive mode using heuristics

**What ICT Directly Adopts**

ICT uses Tost's passive/heuristic mode as the primary interpretation mechanism:
- People observe environmental cues
- Cues trigger simple decision rules (heuristics)
- Heuristics produce quick legitimacy judgments
- Judgments guide behavior without extensive deliberation

ICT adopts the three-dimensional framework but reframes for organizational application:
- Instrumental → "Is this safe?" (risk assessment)
- Relational → "Is this acceptable?" (social fit)
- Moral → "Is this worthwhile?" (meaningful vs. compliance theater)

**What ICT Extends**

1. **Cue sources:** ICT specifies six domains from which legitimacy cues arise
2. **Domain mechanisms:** ICT explains how domains signal legitimacy through structural, signaling, and cognitive mechanisms
3. **Convergence/divergence:** ICT explains when interpretations converge (similar cues, similar heuristics) vs. remain contested (contradictory cues)
4. **Contested equilibrium:** ICT shows how coordination can persist when legitimacy judgments remain divided

**Not Claimed by ICT**

* Full three-stage legitimacy judgment cycle (formation, evaluation, behavioral consequence)
* Individual differences in judgment tendency
* Legitimacy judgments about entities other than practices/actions

**Boundary**

Tost (2011) provides the micro-level cognitive mechanism for how individuals form legitimacy judgments. ICT specifies the environmental conditions (six domains) that provide cues for those judgments and explains how individual judgments aggregate into organizational patterns through distributed memory.

**Citation:**
Tost, L. P. (2011). An integrative model of legitimacy judgments. *Academy of Management Review, 36*(4), 686-710.

---

## Heuristic Processing & Cue-Based Assessment

**Source:** Chaiken (1987); Bitektine (2011); Deephouse et al. (2017)

**Used by ICT**

* **Heuristic-systematic model (Chaiken):** Dual-process framework distinguishing quick heuristic processing from effortful systematic processing
* **Cue-based legitimacy assessment (Bitektine; Deephouse et al.):** People assess organizational legitimacy by reading environmental cues rather than comprehensive information processing
* **Specific heuristics:** Authority ("experts can be trusted"), consensus ("what everyone does is normal"), consistency ("alignment signals reliability")

**What ICT Directly Adopts**

ICT uses the heuristic processing framework to explain how people form legitimacy judgments:

**Heuristics ICT emphasizes:**
1. Authority heuristic: Leadership endorsement signals legitimacy
2. Consensus heuristic: Widespread practice signals safety
3. Consequence heuristic: Rewards/punishments signal what's legitimate
4. Consistency heuristic: Cross-domain alignment signals true priorities
5. Feasibility heuristic: Structural possibility signals expectations
6. Anchoring: Comparison to "normal" determines deviation assessment

**Process:**
- Environmental conditions provide cues
- Cues trigger heuristics (often automatically, without conscious awareness)
- Heuristics produce quick legitimacy assessments
- Assessments guide responses

**What ICT Extends**

1. **Domain specification:** ICT identifies six specific domains that provide legitimacy cues
2. **Cross-domain consistency:** ICT explains why cue consistency across domains accelerates legitimacy convergence
3. **Contradictory cues:** ICT shows how domain misalignment creates enduring contested legitimacy
4. **Cue-based vs. outcome-based learning:** ICT distinguishes learning from cues (before action) from learning from results (after action)

**Not Claimed by ICT**

* Full dual-process models of persuasion or attitude change
* Individual differences in processing tendencies
* Motivated reasoning or defensive processing

**Boundary**

Chaiken, Bitektine, and Deephouse et al. provide the cognitive mechanisms (heuristics, cue processing) for how individuals assess legitimacy. ICT specifies (1) where organizational cues come from (six domains), (2) when cue-based interpretations converge vs. remain contested, and (3) how cue-based learning differs from outcome-based learning in explaining organizational patterns.

**Citations:**
- Chaiken, S. (1987). The heuristic model of persuasion. In M. P. Zanna, J. M. Olson, & C. P. Herman (Eds.), *Social influence: The Ontario Symposium* (Vol. 5, pp. 3–39). Hillsdale, NJ: Lawrence Erlbaum.
- Bitektine, A. (2011). Toward a theory of social judgments of organizations: The case of legitimacy, reputation, and status. *Academy of Management Review, 36*(1), 151-179.
- Deephouse, D. L., Bundy, J., Tost, L. P., & Suchman, M. C. (2017). Organizational legitimacy: Six key questions. In R. Greenwood, C. Oliver, T. B. Lawrence, & R. E. Meyer (Eds.), *The SAGE Handbook of Organizational Institutionalism* (2nd ed., pp. 27-54). SAGE.

---

## Organizational Learning & Memory

**Source:** Levitt & March (1988); Walsh & Ungson (1991); Cyert & March (1963)

**Used by ICT**

* Distributed memory across individuals, culture, structures, ecology (Walsh & Ungson)
* Routines as encoded organizational memory (Levitt & March)
* Competency traps and superstitious learning (Levitt & March)
* Knowledge stickiness (Szulanski, 1996)

**Not Claimed by ICT**

* Outcome-based learning as sufficient explanation for persistence
* Performance feedback as primary driver of change
* Learning necessarily improves adaptation

**Boundary**
Organizational learning focuses on outcome-based learning (try → observe results → encode). ICT focuses on cue-based learning about legitimacy (observe cues → infer legitimacy → shape what gets attempted). The frameworks are complementary: OL explains what happens after action; ICT explains what shapes whether action is attempted.

**Key Distinction**
ICT explains:
1. Why some practices never get tried despite potential benefits (legitimacy cues prevent trial)
2. Why patterns persist despite poor performance (legitimacy cues remain supportive)
3. Contested equilibrium (coordination without legitimacy)
4. Why performance feedback often fails without legitimacy cue shifts

---

## Behavior Engineering / Environmental Supports

**Source:** Gilbert (1978)

**Used by ICT**

* Environmental conditions as primary drivers of behavior (~75% of performance variance)
* Distinction between environmental support and individual repertory
* Six categories of influence (information, instrumentation, motivation × environment/individual)

**Not Claimed by ICT**

* Performance optimization as goal
* Environmental sufficiency (fixing environment guarantees behavior change)
* Individual-level focus

**ICT Extensions**

1. Reframes Gilbert's "capacity" as organizational allocation, not individual trait
2. Adds signaling mechanism (what allocation reveals about priorities)
3. Adds cognitive mechanism (how environment shapes what's thinkable)
4. Adds Norms & Expectations as collective interpretive layer
5. Reframes environmental factors as legitimacy signals requiring cross-domain consistency

---

## Practice Diffusion & Symbolic Adoption

**Source:** Westphal, Gulati, & Shortell (1997)

**Used by ICT**

* Evidence that adoption ≠ internal legitimacy
* Distinction between symbolic and substantive implementation
* Finding that early adopters customize more; late adopters conform more

**Not Claimed by ICT**

* Adoption-stage explanations (why early vs. late differs)
* Field-level diffusion mechanisms
* Mimetic isomorphism across organizations

**Boundary**
Practice diffusion research operates at field level (how practices spread across organizations). ICT operates within organizations (how practices persist or fail through continuous enactment). ICT uses diffusion research as evidence for contested equilibrium but does not explain diffusion itself.

---

# LEDGER GOVERNANCE RULES

## Rule 1: Core Concepts Are Identity-Defining
Core concepts cannot be casually revised, combined, or removed. Any proposed change to a core concept requires explicit theoretical justification and ledger version increment.

## Rule 2: Supporting Concepts May Evolve
Supporting concepts may be refined, elaborated, or added as the theory develops, provided they remain consistent with core logic.

## Rule 3: Imported Concepts Must Be Bounded
Imported concepts must clearly specify:
* What ICT uses from the source theory
* What ICT does not claim
* Where the boundary lies

Imported concepts must never be presented as ICT-original.

## Rule 4: Working Paper Follows Ledger
When working paper and ledger definitions conflict, ledger is authoritative. Working paper may elaborate or provide examples but may not alter canonical definitions without ledger revision.

## Rule 5: Public Explanations May Simplify Language
ICT.html (practitioner introduction) may use simpler language and more accessible examples, but may not:
* Alter canonical definitions
* Add claims not in ledger
* Misrepresent relationships between concepts

## Rule 6: Version Control
* Ledger must be versioned (Major.Minor)
* Major version increments when core concepts change
* Minor version increments when supporting concepts change or clarifications are added
* All changes must be documented in version history

## Rule 7: Cross-Reference Requirement
When academic papers cite ICT, they should reference the ledger version used to ensure semantic consistency over time.

---

## Versioning History

**Version 1.0** (Initial)
* First canonical ledger establishing core and supporting concepts

**Version 1.1** (January 2026)
* Fixed: Clarified "Distributed Memory" as primary term; "Structural Memory" as acceptable alternative
* Fixed: Standardized "Change" definition wording
* Added: Canonical definitions for each of the six domains
* Added: "Recursive Function" explicit to Conditions and Norms
* Added: "Structures vs. Patterns" relationship clarification
* Added: "Ontological Status" explanation for Legitimacy
* Expanded: "Stewardship of Conditions" with what stewards can/cannot do
* Added: Three mechanisms (Structural, Signaling, Cognitive) detailed for each domain
* Added: Terminology note on "organizational memory" vs. "distributed memory"
* Added: Governance rules for version control and cross-referencing

**Version 1.2** (January 2026)
* Added: "Observable" specification for Conditions (capable of being perceived by a person through any sense)
* Added: Boundary cases distinguishing observable conditions from internal states
* Added: Methodological justification for observable conditions focus
* Added: Norms disambiguation (lowercase vs. capitalized usage)
* Addressed: Peer review vulnerabilities on Conditions operationalization and norms conceptual clarity

**Version 1.3** (January 2026)
* **CRITICAL: Acknowledged independent discovery** - Added recognition that Haack, Schilke, & Zucker (2021) independently discovered contested equilibrium (which they term "validity-consensus incongruity")
* **Added: Multi-Level Legitimacy Theory** as imported supporting concept (Haack et al., 2021)
* **Expanded: Legitimacy measurement operationalization** - Added three-level measurement framework (individual/propriety, collective/consensus, institutional/validity)
* **Added: Empirical detection methods** for contested equilibrium
* **Added: Spectrum operationalization** - Specified thresholds for contested/routine/taken-for-granted legitimacy
* **Citation added:** Haack, P., Schilke, O., & Zucker, L. G. (2021). Legitimacy revisited: Disentangling propriety, validity, and consensus. Journal of Management Studies, 58(3), 749-781.
* **Addressed: Peer review vulnerabilities** on legitimacy measurement, operationalization gaps, and theoretical tensions

**Version 1.4** (January 2026)
* **MAJOR: Fully specified Interpretation mechanisms** - Replaced brief placeholder definition with comprehensive specification of cue-based heuristic processing
* **Added: Legitimacy Judgment Process** as imported supporting concept (Tost, 2011)
* **Added: Heuristic Processing & Cue-Based Assessment** as imported supporting concept (Chaiken, 1987; Bitektine, 2011; Deephouse et al., 2017)
* **Specified: Two processing modes** - Passive/heuristic (primary) and Evaluative/systematic (secondary)
* **Specified: Six heuristics** - Authority, consensus, consequence, consistency, feasibility, anchoring
* **Specified: Five-step interpretation process** - Cue observation → Heuristic application → Legitimacy judgment → Response → New conditions (recursive loop)
* **Specified: Convergence/divergence mechanisms** - How interpretations converge (similar cues + similar heuristics) or remain contested (contradictory cues)
* **Specified: Three legitimacy dimensions** - Safe, acceptable, worthwhile (adapted from Tost's instrumental/relational/moral)
* **Clarified: ICT is not a theory OF interpretation** - ICT uses interpretation mechanisms from existing research
* **Citations added:** Tost (2011), Chaiken (1987), Bitektine (2011), Deephouse et al. (2017)
* **Addressed: Peer review vulnerability** on interpretation underdevelopment and theoretical thinness

**Version 1.5** (January 2026)
* **MAJOR: Fully specified Agency mechanisms** - Replaced brief definition with comprehensive bounded agency specification
* **Added: Bounded Agency Theory** as imported supporting concept (Evans, 2007; 2017; Biesta & Tedder, 2007)
* **Specified: Ontological status** - Agency is individual, not collective (parallel to distributed memory)
* **Specified: What bounds agency** - Six domains constrain perceived possibility space through direct limitation, cognitive framing, perceived risk, horizon narrowing
* **Specified: What enables agency** - Perceived possibilities, available resources, risk tolerance, temporal horizon, identity/values create variation in responses
* **Specified: Agency as process** - Continuous cycle shaped by past experiences, present context, perceived futures
* **Specified: When agency produces different outcomes** - Same conditions constrain range; agency determines which response within range
* **Specified: How agency relates to change** - Aggregated individual agency transforms structure when structural room exists
* **Resolved: Determinism problem** - ICT is neither deterministic (agency produces variation) nor voluntaristic (agency is bounded); structure and agency operate together
* **Clarified: ICT is not a theory OF agency** - ICT uses bounded agency framework from existing research
* **Citations added:** Evans (2007, 2017), Biesta & Tedder (2007)
* **Addressed: Peer review vulnerabilities** on theoretical tension, scope ambiguity, determinism problem

**Version 1.6** (January 2026)
* **CRITICAL CONCEPTUAL REFRAMING: Structure (noun) vs. Structuring (verb)** - Fundamentally clarified that structure as noun is communication convenience; what actually happens is structuring (verb) as continuous process
* **CRITICAL CLARIFICATION: Contested equilibrium IS a structure** - Corrected misconception that contested equilibrium means "not a structure"; it describes a structure with specific character (high coordination, low legitimacy consensus)
* **Revised: Structures section** - Added extensive clarification that all patterns being continuously enacted ARE structures; they vary in character (coordination level, legitimacy consensus, stability), not in whether they exist
* **Revised: Contested Equilibrium section** - Added explicit statement that structuring IS happening (people read cues, form judgments, respond, create new cues); distributed memory HAS formed; pattern IS being reproduced; structure contains the contestation as part of its content
* **Clarified: What varies across structures** - Coordination level (low/moderate/high), legitimacy consensus (low/moderate/high), coordination-legitimacy alignment (aligned vs. misaligned)
* **Key insight:** The structure exists. It just contains the contestation as part of what's being enacted. Performance reviews ARE a structure—one with high coordination but low legitimacy consensus.
* **Addressed: Fundamental misconception** that would undermine theory's explanatory power by excluding contested equilibrium from being structural

**Version 1.7** (January 2026)
* **CRITICAL CLARIFICATION: Structure = Institution** - Codified that "structure" (ICT) and "institution" (IT) refer to the same phenomenon: patterns maintained through legitimacy-based continuous enactment
* **CRITICAL CLARIFICATION: Multi-level structuring** - Explicitly stated that structuring happens at ALL levels simultaneously (individual, family, team, org, field, society); NO scope restriction
* **Added: Relationship to Institutional Theory** - ICT is mechanistic specification and operational elaboration of IT, not different ontological entity (analogy: IT:ICT :: Newtonian Physics:Engineering Mechanics)
* **Added: ICT's contributions** - Distributed memory (HOW), six domains (WHERE), cue-based interpretation (MECHANISM), contested equilibrium (FORMATION), bounded agency, process emphasis
* **Added: Measurement framework transfer** - Explicit statement that methods transfer directly from IT (Tolbert & Zucker 1996, Scott 2001, Haack et al. 2021)
* **Added: Palimpsest concept** - Individuals exist within layered, overlapping structures operating simultaneously (family, team, org, professional, cultural, political)
* **Added: Scott's three pillars mapping** - Table showing regulative→Capacity/Motivation, normative→Norms/Motivation, cultural-cognitive→Distributed Memory
* **Clarified: Why different terms** - Different scholarly traditions, different emphasis (stability vs. process), same mechanisms
* **Key insight:** Structure and institution are the same phenomenon at different scales; same mechanisms operate at all levels; ICT adds mechanistic specification, not ontological distinctiveness
* **Addressed: Scope confusion** - Eliminated false constraint that ICT operates only at organizational level; made explicit that all levels use same structuring mechanisms

**Version 1.8** (January 2026)
* **MAJOR: Added Empirical Measurement section** - Comprehensive specification of how to measure structuration with process ontology (addresses peer review critique on measurement methods)
* **Added: Property variable + process framework** - Codified Tolbert & Zucker's solution: structuration is BOTH measurable at a moment (property) AND continuous process (verb)
* **Added: Dimensions of structuration** - Four measurable dimensions: coordination level, legitimacy consensus, stability, taken-for-grantedness
* **Added: Three-stage framework specification** - Pre-institutionalization, semi-institutionalization, full institutionalization characteristics with empirical indicators
* **Added: Contested equilibrium measurement** - Specific pattern of measurements indicating coordination-legitimacy misalignment
* **Added: Six measurement methods** - (1) Legitimacy surveys (multi-level), (2) Behavioral variance analysis, (3) Effort tracking, (4) Disruption resistance tests, (5) Survival across turnover, (6) Domain cue consistency
* **Added: Domain cue consistency method** - ICT-specific contribution measuring alignment across six domains
* **Added: Integrated measurement strategy** - Minimum viable (3 methods) and comprehensive (7 methods) approaches
* **Added: Contested equilibrium detection criteria** - High coordination + low consensus + enforcement-dependent + regulative-heavy domains
* **Key insight:** Methods transfer from institutional theory (same phenomenon, same methods); ICT adds domain cue consistency for organizational contexts
* **Addressed: Peer review vulnerability** on lack of empirical methods consistent with process ontology

**Version 1.9** (January 2026)
* **CRITICAL CLARIFICATION: Structure-Distributed Memory relationship** - Radically clarified that structure and distributed memory are not two separate phenomena but two analytically distinguishable aspects of structuration (behavioral vs. cognitive)
* **Revised: Distributed Memory section** - Complete rewrite emphasizing it's the cognitive aspect of structuration, not a separate phenomenon
* **Added: Wave analogy** - Structure has behavioral aspect (coordination) and cognitive aspect (distributed memory) like wave has amplitude and frequency—different measurable properties of one phenomenon
* **Added: Why distinction matters** - (1) Contested equilibrium requires it, (2) Maps to cultural-cognitive pillar, (3) Specifies mechanism, (4) Enables precise measurement
* **Added: What distributed memory contains** - Safety, acceptability, worthwhileness judgments, context specificity, implementation knowledge
* **Added: How memory forms** - Direct experience, vicarious observation, social transmission, cue interpretation, overlapping learning
* **Clarified: Difference from organizational learning** - OL focuses on outcome-based learning (after action), ICT focuses on cue-based learning about legitimacy (before action)
* **Added: Measurement specification** - Legitimacy surveys for consensus, interviews for content, narrative analysis for judgments
* **Updated: Key Clarifications in Structures section** - Added explicit statement that structure and distributed memory are aspects, not separate phenomena; distinction is analytical not ontological
* **Key insight:** The analytical distinction enables explaining contested equilibrium (high behavioral coordination, low legitimacy consensus) while clarifying they're not two things that happen to co-occur
* **Addressed: Peer review vulnerability** on apparent conceptual redundancy between structure and distributed memory

**Version 2.0** (January 2026)
* **MAJOR: Added three subsections addressing coordination-legitimacy measurement critique**
* **Added: "Addressing Social Desirability Bias" subsection** - Six mitigation strategies: triangulation (primary), anonymous surveys, indirect measurement, behavioral proxies, safe space inquiry, variance as signal
* **Added: "Observable Behavioral Indicators" subsection** - 10 contested equilibrium behaviors and 10 taken-for-granted behaviors with systematic observation methods and coding schemes
* **Added: "Measurement Thresholds" subsection** - Acknowledged current thresholds (80% coordination, SD values) as heuristics requiring empirical validation; specified context factors affecting thresholds; provided guidance for researchers
* **Key shift: Behavioral indicators as PRIMARY, surveys as SECONDARY/TRIANGULATION** - Addresses critique that self-reports are unreliable due to social desirability bias
* **Contested equilibrium behavioral indicators:** Minimal compliance, workarounds, rapid abandonment when enforcement weakens, no voluntary defense, "required" explanations, repeated newcomer questions, private-public divergence, mockery/cynicism, high variance in quality, differential adoption
* **Taken-for-granted behavioral indicators:** Voluntary adoption beyond minimum, continues without enforcement, active defense, "value" explanations, newcomers stop questioning, public-private alignment, genuine enthusiasm, low variance in quality, automatic restoration, uniform adoption
* **Threshold guidance:** 80% coordination and SD thresholds are operational heuristics based on theoretical reasoning; require systematic empirical validation; vary based on network density, enforcement strength, switching costs, task criticality
* **Transparency about empirical work needed:** Long-term goal is empirically validated, context-specific thresholds through systematic studies, meta-analysis, longitudinal tracking
* **Key insight:** Observable behaviors provide robust evidence of contested vs. taken-for-granted legitimacy without relying on self-reports, making measurement more defensible against social desirability bias concerns
* **Addressed: Peer review vulnerability** on empirical challenges distinguishing coordination from legitimacy, social desirability bias in self-reports, and threshold ambiguity

---

## End of Concept Ledger v2.0